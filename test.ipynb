{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e699474e",
   "metadata": {},
   "source": [
    "Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0e0404b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "c:\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
      "C:\\Users\\ikchr\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas_ta\\__init__.py:7: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import get_distribution, DistributionNotFound\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from loguru import logger\n",
    "import MetaTrader5 as mt5\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "from typing import Dict, Any, Optional, Tuple, List\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback, CheckpointCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize, VecEnv\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "from __future__ import annotations\n",
    "import math\n",
    "from gymnasium import spaces\n",
    "from pathlib import Path\n",
    "import pandas_ta as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78665166",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_dt = datetime.now()\n",
    "start_dt = end_dt - timedelta(days=730)\n",
    "symbol_name = \"XAUUSDm\"\n",
    "is_connected = False\n",
    "timeframe = \"M15\"\n",
    "data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af83b24f",
   "metadata": {},
   "source": [
    "Initialize MT5 and connect to MT5 Broker account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "441497e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-27 19:53:29.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mMT5 initialization successful\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if not mt5.initialize(\n",
    "    login=210888620,\n",
    "    password=\"S@jasper&12345\",\n",
    "    server=\"Exness-MT5Trial9\"\n",
    "):\n",
    "    logger.error(f\"MT5 initialization failed: {mt5.last_error()}\")\n",
    "            \n",
    "    # Get account info\n",
    "    account_info = mt5.account_info()\n",
    "    if account_info is None:\n",
    "        logger.error(\"Failed to get account information\")\n",
    "    \n",
    "        symbol_info = mt5.symbol_info(symbol_name)\n",
    "        if symbol_info is None:\n",
    "            logger.warning(f\"Symbol {symbol_name} not found\")\n",
    "        else:\n",
    "            mt5.symbol_select(symbol_name, True)\n",
    "    \n",
    "    is_connected = True\n",
    "    logger.info(f\"Connected to MT5: Account {account_info.login},\"\n",
    "                f\"Balance: {account_info.balance}, \"\n",
    "                f\"Server: {account_info.server}\")\n",
    "else:\n",
    "    logger.info(\"MT5 initialization successful\")\n",
    "    is_connected = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822befc1",
   "metadata": {},
   "source": [
    "Get historical market data.\n",
    "        \n",
    "Args:\n",
    "    symbol: Trading symbol\n",
    "    timeframe: Timeframe (M1, M5, M15, M30, H1, H4, D1)\n",
    "    start_date: Start date for data\n",
    "    end_date: End date for data\n",
    "    count: Number of bars to retrieve\n",
    "    \n",
    "Returns:\n",
    "    DataFrame with OHLCV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f6c8020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-27 19:53:35.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mRetrieved 47224 bars for XAUUSDm (M15)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if not is_connected:\n",
    "    logger.error(\"Not connected to MT5\")\n",
    "else:        \n",
    "    try:\n",
    "        # Map timeframe strings to MT5 constants\n",
    "        timeframe_map = {\n",
    "            \"M1\": mt5.TIMEFRAME_M1,\n",
    "            \"M5\": mt5.TIMEFRAME_M5,\n",
    "            \"M15\": mt5.TIMEFRAME_M15,\n",
    "            \"M30\": mt5.TIMEFRAME_M30,\n",
    "            \"H1\": mt5.TIMEFRAME_H1,\n",
    "            \"H4\": mt5.TIMEFRAME_H4,\n",
    "            \"D1\": mt5.TIMEFRAME_D1\n",
    "        }\n",
    "        \n",
    "        mt5_timeframe = timeframe_map.get(timeframe, mt5.TIMEFRAME_H1)\n",
    "        \n",
    "        # Get data\n",
    "        rates = mt5.copy_rates_range(symbol_name, mt5_timeframe, start_dt, end_dt)\n",
    "        \n",
    "        if rates is None or len(rates) == 0:\n",
    "            logger.warning(f\"No data retrieved for {symbol_name}\")\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(rates)\n",
    "        df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "        df.set_index('time', inplace=True)\n",
    "        \n",
    "        # Rename columns to standard format\n",
    "        df.rename(columns={\n",
    "            'open': 'open',\n",
    "            'high': 'high', \n",
    "            'low': 'low',\n",
    "            'close': 'close',\n",
    "            'tick_volume': 'volume'\n",
    "        }, inplace=True)\n",
    "        \n",
    "        logger.info(f\"Retrieved {len(df)} bars for {symbol_name} ({timeframe})\")\n",
    "        data = df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error retrieving historical data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bec49153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-27 19:53:41.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mTraning Data:                          open      high       low     close  volume  spread  \\\n",
      "time                                                                          \n",
      "2023-08-28 19:00:00  1919.521  1920.308  1919.521  1919.877     447     200   \n",
      "2023-08-28 19:15:00  1919.876  1920.547  1919.875  1920.396     516     200   \n",
      "2023-08-28 19:30:00  1920.398  1920.503  1919.774  1920.052     558     200   \n",
      "2023-08-28 19:45:00  1920.032  1920.127  1919.457  1919.659     593     200   \n",
      "2023-08-28 20:00:00  1919.676  1920.208  1919.676  1919.972     337     200   \n",
      "...                       ...       ...       ...       ...     ...     ...   \n",
      "2025-08-27 15:45:00  3388.838  3388.838  3386.470  3387.898    1453     160   \n",
      "2025-08-27 16:00:00  3387.917  3389.719  3387.478  3388.930    1325     160   \n",
      "2025-08-27 16:15:00  3388.944  3391.179  3388.111  3391.153    1354     160   \n",
      "2025-08-27 16:30:00  3391.107  3395.962  3390.132  3394.525    2248     160   \n",
      "2025-08-27 16:45:00  3394.465  3398.823  3393.991  3396.958    2104     160   \n",
      "\n",
      "                     real_volume  \n",
      "time                              \n",
      "2023-08-28 19:00:00            0  \n",
      "2023-08-28 19:15:00            0  \n",
      "2023-08-28 19:30:00            0  \n",
      "2023-08-28 19:45:00            0  \n",
      "2023-08-28 20:00:00            0  \n",
      "...                          ...  \n",
      "2025-08-27 15:45:00            0  \n",
      "2025-08-27 16:00:00            0  \n",
      "2025-08-27 16:15:00            0  \n",
      "2025-08-27 16:30:00            0  \n",
      "2025-08-27 16:45:00            0  \n",
      "\n",
      "[47224 rows x 7 columns]\u001b[0m\n",
      "\u001b[32m2025-08-27 19:53:41.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mTrain Data:                          open      high       low     close  volume  spread  \\\n",
      "time                                                                          \n",
      "2023-08-28 19:00:00  1919.521  1920.308  1919.521  1919.877     447     200   \n",
      "2023-08-28 19:15:00  1919.876  1920.547  1919.875  1920.396     516     200   \n",
      "2023-08-28 19:30:00  1920.398  1920.503  1919.774  1920.052     558     200   \n",
      "2023-08-28 19:45:00  1920.032  1920.127  1919.457  1919.659     593     200   \n",
      "2023-08-28 20:00:00  1919.676  1920.208  1919.676  1919.972     337     200   \n",
      "...                       ...       ...       ...       ...     ...     ...   \n",
      "2025-04-03 12:30:00  3078.715  3079.162  3061.916  3065.901   11159     159   \n",
      "2025-04-03 12:45:00  3065.799  3080.327  3065.030  3076.261   11092     159   \n",
      "2025-04-03 13:00:00  3076.233  3076.408  3054.052  3059.401   12328     159   \n",
      "2025-04-03 13:15:00  3059.393  3069.694  3056.182  3065.313   10260     159   \n",
      "2025-04-03 13:30:00  3065.374  3088.933  3064.163  3086.659   16579     159   \n",
      "\n",
      "                     real_volume  \n",
      "time                              \n",
      "2023-08-28 19:00:00            0  \n",
      "2023-08-28 19:15:00            0  \n",
      "2023-08-28 19:30:00            0  \n",
      "2023-08-28 19:45:00            0  \n",
      "2023-08-28 20:00:00            0  \n",
      "...                          ...  \n",
      "2025-04-03 12:30:00            0  \n",
      "2025-04-03 12:45:00            0  \n",
      "2025-04-03 13:00:00            0  \n",
      "2025-04-03 13:15:00            0  \n",
      "2025-04-03 13:30:00            0  \n",
      "\n",
      "[37779 rows x 7 columns]\u001b[0m\n",
      "\u001b[32m2025-08-27 19:53:41.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mEvaluation Data:                          open      high       low     close  volume  spread  \\\n",
      "time                                                                          \n",
      "2025-04-03 13:45:00  3086.717  3093.478  3084.257  3086.168   13307     159   \n",
      "2025-04-03 14:00:00  3086.698  3116.576  3086.123  3114.317   12490     159   \n",
      "2025-04-03 14:15:00  3114.292  3126.659  3110.976  3125.381   13030     159   \n",
      "2025-04-03 14:30:00  3125.345  3127.930  3117.600  3123.673   11088     159   \n",
      "2025-04-03 14:45:00  3123.710  3135.605  3123.710  3128.939   10562     159   \n",
      "...                       ...       ...       ...       ...     ...     ...   \n",
      "2025-08-27 15:45:00  3388.838  3388.838  3386.470  3387.898    1453     160   \n",
      "2025-08-27 16:00:00  3387.917  3389.719  3387.478  3388.930    1325     160   \n",
      "2025-08-27 16:15:00  3388.944  3391.179  3388.111  3391.153    1354     160   \n",
      "2025-08-27 16:30:00  3391.107  3395.962  3390.132  3394.525    2248     160   \n",
      "2025-08-27 16:45:00  3394.465  3398.823  3393.991  3396.958    2104     160   \n",
      "\n",
      "                     real_volume  \n",
      "time                              \n",
      "2025-04-03 13:45:00            0  \n",
      "2025-04-03 14:00:00            0  \n",
      "2025-04-03 14:15:00            0  \n",
      "2025-04-03 14:30:00            0  \n",
      "2025-04-03 14:45:00            0  \n",
      "...                          ...  \n",
      "2025-08-27 15:45:00            0  \n",
      "2025-08-27 16:00:00            0  \n",
      "2025-08-27 16:15:00            0  \n",
      "2025-08-27 16:30:00            0  \n",
      "2025-08-27 16:45:00            0  \n",
      "\n",
      "[9445 rows x 7 columns]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Split data for training and validation\n",
    "logger.info(f'Traning Data: {data}')\n",
    "\n",
    "split_point = int(len(data) * 0.8)\n",
    "train_data = data.iloc[:split_point]\n",
    "eval_data = data.iloc[split_point:]\n",
    "\n",
    "logger.info(f'Train Data: {train_data}')\n",
    "logger.info(f'Evaluation Data: {eval_data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73a277c",
   "metadata": {},
   "source": [
    "State Feature Extractor\n",
    "=======================\n",
    "\n",
    "This module extracts and processes features for the trading environment state.\n",
    "It handles technical indicators, price features, and time-based features.\n",
    "\n",
    "Features include:\n",
    "- Price data (OHLCV)\n",
    "- Technical indicators (SMA, EMA, RSI, MACD, Bollinger Bands, ATR)\n",
    "- Time features (hour, day of week, etc.)\n",
    "- Normalized and scaled features\n",
    "\n",
    "Author: PPO Trading System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b503c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-27 19:58:25.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mState feature extractor initialized\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "config_path: str = \"config/model_config.yaml\"\n",
    "# load main config\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    \n",
    "feature_config = config['environment']['features']\n",
    "\n",
    "# Feature scaling parameters (learned during first extraction)\n",
    "feature_stats = {}\n",
    "is_fitted = False\n",
    "\n",
    "# Track minimum data requirements for each indicator\n",
    "min_periods = {\n",
    "    'sma_5': 5, 'sma_20': 20, 'sma_50': 50,\n",
    "    'ema_12': 12, 'ema_26': 26,\n",
    "    'rsi_14': 14, 'macd': 26, 'atr_14': 14,\n",
    "    'bb_upper': 20, 'bb_lower': 20\n",
    "}\n",
    "\n",
    "logger.info(\"State feature extractor initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f6e7cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _validate_input_data(data: pd.DataFrame) -> bool:\n",
    "    required_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "    for col in required_cols:\n",
    "        if col not in data.columns:\n",
    "            logger.error(f\"Missing required column: {col}\")\n",
    "            return False\n",
    "    \n",
    "    # Check for NaN in essential columns\n",
    "    essential_nan = data[required_cols].isnull().sum().sum()\n",
    "    if essential_nan > 0:\n",
    "        logger.warning(f\"Found {essential_nan} NaN values in essential columns\")\n",
    "        # Fill essential NaN with forward then backward fill\n",
    "        data[required_cols] = data[required_cols].ffill().bfill()\n",
    "    \n",
    "    return True\n",
    "    \n",
    "def _add_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    indicators = feature_config.get('technical_indicators', [])\n",
    "    n_rows = len(df)\n",
    "    \n",
    "    for indicator in indicators:\n",
    "        try:\n",
    "            # Skip indicators that require more data than available\n",
    "            min_periods = min_periods.get(indicator, 1)\n",
    "            if n_rows < min_periods:\n",
    "                logger.warning(f\"Skipping {indicator}: {n_rows} < {min_periods}\")\n",
    "                continue\n",
    "            \n",
    "            if ta:\n",
    "                # Use pandas_ta if available\n",
    "                if indicator == 'sma_5':\n",
    "                    df['sma_5'] = ta.sma(df['close'], length=5)\n",
    "                elif indicator == 'sma_20':\n",
    "                    df['sma_20'] = ta.sma(df['close'], length=20)\n",
    "                elif indicator == 'sma_50':\n",
    "                    df['sma_50'] = ta.sma(df['close'], length=50)\n",
    "                elif indicator == 'ema_12':\n",
    "                    df['ema_12'] = ta.ema(df['close'], length=12)\n",
    "                elif indicator == 'ema_26':\n",
    "                    df['ema_26'] = ta.ema(df['close'], length=26)\n",
    "                elif indicator == 'rsi_14':\n",
    "                    df['rsi_14'] = ta.rsi(df['close'], length=14)\n",
    "                elif indicator == 'macd':\n",
    "                    macd_df = ta.macd(df['close'], fast=12, slow=26, signal=9)\n",
    "                    df['macd'] = macd_df['MACD_12_26_9']\n",
    "                    df['macd_signal'] = macd_df['MACDs_12_26_9']\n",
    "                elif indicator in ['bb_upper', 'bb_lower']:\n",
    "                    bbands = ta.bbands(df['close'], length=20, std=2)\n",
    "                    df['bb_upper'] = bbands['BBU_20_2.0']\n",
    "                    df['bb_lower'] = bbands['BBL_20_2.0']\n",
    "                elif indicator == 'atr_14':\n",
    "                    df['atr_14'] = ta.atr(df['high'], df['low'], df['close'], length=14)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to calculate indicator {indicator}: {e}\")\n",
    "    \n",
    "    # Add price-based features with robust calculation\n",
    "    df['price_change'] = df['close'].pct_change()\n",
    "    \n",
    "    # Handle division by zero in high_low_ratio\n",
    "    high_low_ratio = np.where(\n",
    "        df['low'] != 0, \n",
    "        df['high'] / df['low'], \n",
    "        np.where(df['high'] != 0, 1.0, 1.0)\n",
    "    )\n",
    "    df['high_low_ratio'] = high_low_ratio\n",
    "    \n",
    "    # Volume features with robust handling\n",
    "    df['volume_sma'] = ta.sma(df['volume'], length=20) if ta else df['volume'].rolling(window=20).mean()\n",
    "    \n",
    "    # Handle division by zero in volume_ratio\n",
    "    volume_ratio = np.where(\n",
    "        (df['volume_sma'] != 0) & (~np.isclose(df['volume_sma'], 0)),\n",
    "        df['volume'] / df['volume_sma'],\n",
    "        np.where(df['volume'] != 0, 1.0, 0.0)\n",
    "    )\n",
    "    df['volume_ratio'] = volume_ratio\n",
    "    \n",
    "    # Volatility features\n",
    "    df['volatility'] = df['price_change'].rolling(window=20, min_periods=1).std()\n",
    "    \n",
    "    # Handle division by zero in price_position\n",
    "    price_range = df['high'] - df['low']\n",
    "    price_position = np.where(\n",
    "        price_range != 0,\n",
    "        (df['close'] - df['low']) / price_range,\n",
    "        np.where(df['close'] != 0, 0.5, 0.5)\n",
    "    )\n",
    "    df['price_position'] = price_position\n",
    "    \n",
    "    return df\n",
    "\n",
    "def _handle_nan_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Fill NaN values with appropriate methods\n",
    "    for col in df.columns:\n",
    "        if df[col].isnull().any():\n",
    "            # For price-based columns, use forward/backward fill\n",
    "            if col in ['open', 'high', 'low', 'close', 'volume']:\n",
    "                df[col] = df[col].ffill().bfill()\n",
    "            # For technical indicators, use the mean of the column\n",
    "            else:\n",
    "                col_mean = df[col].mean()\n",
    "                if not pd.isna(col_mean):\n",
    "                    df[col] = df[col].fillna(col_mean)\n",
    "                else:\n",
    "                    # If mean is also NaN, use a default value\n",
    "                    df[col] = df[col].fillna(0)\n",
    "    \n",
    "    # Check for infinite values\n",
    "    inf_mask = np.isinf(df.values)\n",
    "    if np.any(inf_mask):\n",
    "        logger.warning(f\"Found {inf_mask.sum()} infinite values in features\")\n",
    "        df = df.replace([np.inf, -np.inf], np.nan)\n",
    "        df = df.ffill().bfill().fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def _normalize_features(data: pd.DataFrame, is_fitted: bool) -> pd.DataFrame:\n",
    "    \"\"\"Normalize features using z-score normalization with robust handling.\"\"\"\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Features that should not be normalized (already in good range)\n",
    "    skip_normalization = ['is_weekend', 'is_month_end', 'is_quarter_end', \n",
    "                        'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos']\n",
    "    \n",
    "    # Features that should be normalized\n",
    "    normalize_features = [col for col in df.select_dtypes(include=[np.number]).columns \n",
    "                        if col not in skip_normalization]\n",
    "    \n",
    "    if not is_fitted:\n",
    "        # Calculate statistics on first run\n",
    "        feature_stats = {}\n",
    "        for feature in normalize_features:\n",
    "            if feature in df.columns:\n",
    "                values = df[feature].dropna()\n",
    "                if len(values) > 0:\n",
    "                    # Handle cases where std is zero or very small\n",
    "                    std = values.std()\n",
    "                    if std < 1e-8:  # Very small standard deviation\n",
    "                        std = 1.0  # Avoid division by zero\n",
    "                    \n",
    "                    feature_stats[feature] = {\n",
    "                        'mean': values.mean(),\n",
    "                        'std': std\n",
    "                    }\n",
    "                else:\n",
    "                    # If no valid values, use defaults\n",
    "                    feature_stats[feature] = {'mean': 0, 'std': 1.0}\n",
    "        is_fitted = True\n",
    "        logger.info(f\"Feature normalization parameters fitted for {len(feature_stats)} features\")\n",
    "    \n",
    "    # Apply normalization\n",
    "    for feature, stats in feature_stats.items():\n",
    "        if feature in df.columns:\n",
    "            # Handle cases where feature values are constant\n",
    "            if stats['std'] < 1e-8:\n",
    "                df[feature] = 0  # Set to zero if no variation\n",
    "            else:\n",
    "                df[feature] = (df[feature] - stats['mean']) / stats['std']\n",
    "    \n",
    "    return df\n",
    "\n",
    "def _add_time_features(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add time-based features.\"\"\"\n",
    "    df = data.copy()\n",
    "    \n",
    "    time_features = feature_config.get('time_features', [])\n",
    "    \n",
    "    # Ensure index is datetime\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        # common timestamp column names to try\n",
    "        ts_candidates = [c for c in ('timestamp', 'time', 'date', 'datetime') if c in df.columns]\n",
    "        coerced = False\n",
    "        for col in ts_candidates:\n",
    "            try:\n",
    "                df.index = pd.to_datetime(df[col])\n",
    "                coerced = True\n",
    "                break\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        if not coerced:\n",
    "            # Try to coerce the existing index\n",
    "            try:\n",
    "                df.index = pd.to_datetime(df.index)\n",
    "                coerced = True\n",
    "            except Exception:\n",
    "                coerced = False\n",
    "\n",
    "        if not coerced:\n",
    "            logger.warning(\"Could not coerce a DatetimeIndex from data. \"\n",
    "                        \"Time features will be omitted. Provide a DatetimeIndex or a 'timestamp' column.\")\n",
    "            \n",
    "    for feature in time_features:\n",
    "        try:\n",
    "            if feature == 'hour_of_day':\n",
    "                df['hour_of_day'] = df.index.hour\n",
    "            elif feature == 'day_of_week':\n",
    "                df['day_of_week'] = df.index.dayofweek\n",
    "            elif feature == 'day_of_month':\n",
    "                df['day_of_month'] = df.index.day\n",
    "            elif feature == 'month_of_year':\n",
    "                df['month_of_year'] = df.index.month\n",
    "            elif feature == 'is_weekend':\n",
    "                df['is_weekend'] = (df.index.dayofweek >= 5).astype(int)\n",
    "            elif feature == 'is_month_end':\n",
    "                df['is_month_end'] = df.index.is_month_end.astype(int)\n",
    "            elif feature == 'is_quarter_end':\n",
    "                df['is_quarter_end'] = df.index.is_quarter_end.astype(int)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to calculate time feature {feature}: {e}\")\n",
    "    \n",
    "    # Cyclical encoding for time features\n",
    "    if 'hour_of_day' in df.columns:\n",
    "        df['hour_sin'] = np.sin(2 * np.pi * df['hour_of_day'] / 24)\n",
    "        df['hour_cos'] = np.cos(2 * np.pi * df['hour_of_day'] / 24)\n",
    "    \n",
    "    if 'day_of_week' in df.columns:\n",
    "        df['dow_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "        df['dow_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def _select_features(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Select only the configured features.\"\"\"\n",
    "    # Get all configured features\n",
    "    price_features = feature_config.get('price_features', [])\n",
    "    technical_indicators = feature_config.get('technical_indicators', [])\n",
    "    time_features = feature_config.get('time_features', [])\n",
    "    \n",
    "    # Add derived features\n",
    "    derived_features = ['price_change', 'high_low_ratio', 'volume_ratio', 'volatility', 'price_position']\n",
    "    \n",
    "    # Do NOT add cyclical_features manually, they are already created in _add_time_features\n",
    "    all_features = (price_features + technical_indicators + time_features + derived_features)\n",
    "    \n",
    "    # Deduplicate while preserving order\n",
    "    all_features = list(dict.fromkeys(all_features))\n",
    "    \n",
    "    # Select only existing features\n",
    "    existing_features = [f for f in all_features if f in data.columns]\n",
    "    \n",
    "    if not existing_features:\n",
    "        logger.warning(\"No configured features found in data, using all numeric columns\")\n",
    "        existing_features = list(data.select_dtypes(include=[np.number]).columns)\n",
    "    \n",
    "    logger.info(f\"Selected {len(existing_features)} features: {existing_features}\")\n",
    "    return data[existing_features]\n",
    "\n",
    "def get_feature_importance(model, feature_names: List[str]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculate feature importance if the model supports it.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model with feature_importances_ attribute\n",
    "        feature_names: List of feature names\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping feature names to importance scores\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importances = model.feature_importances_\n",
    "            return dict(zip(feature_names, importances))\n",
    "        else:\n",
    "            logger.warning(\"Model does not support feature importance calculation\")\n",
    "            return {}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error calculating feature importance: {e}\")\n",
    "        return {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616c9c9f",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Reward Functions\n",
    "================\n",
    "\n",
    "This module implements various reward functions for the PPO trading agent.\n",
    "The reward function is crucial for training the agent to make profitable trades.\n",
    "\n",
    "Available reward strategies:\n",
    "- Profit-based rewards\n",
    "- Sharpe ratio-based rewards\n",
    "- Risk-adjusted returns\n",
    "- Custom composite rewards\n",
    "\n",
    "Author: PPO Trading System\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da3de502",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-27 20:17:23.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mReward calculator initialized\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "reward_config = config['environment']['reward_function']\n",
    "params = reward_config['parameters']\n",
    "\n",
    "# Tracking variables\n",
    "previous_portfolio_value = None\n",
    "returns_history = []\n",
    "max_returns_history = 1000\n",
    "\n",
    "logger.info(f\"Reward calculator initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe4871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _adapt_parameters() -> None:\n",
    "    \"\"\"Adapt reward parameters based on recent performance.\"\"\"\n",
    "    if len(returns_history) < 50:\n",
    "        return\n",
    "    \n",
    "    recent_returns = np.array(returns_history[-50:])\n",
    "    \n",
    "    # Analyze performance\n",
    "    mean_return = np.mean(recent_returns)\n",
    "    volatility = np.std(recent_returns)\n",
    "    sharpe = mean_return / (volatility + 1e-8)\n",
    "    \n",
    "    # Adapt drawdown penalty based on recent volatility\n",
    "    if volatility > 0.05:  # High volatility\n",
    "        params['drawdown_penalty'] = min(params['drawdown_penalty'] * 1.1, 5.0)\n",
    "    elif volatility < 0.01:  # Low volatility\n",
    "        params['drawdown_penalty'] = max(params['drawdown_penalty'] * 0.9, 0.1)\n",
    "    \n",
    "    # Adapt profit weight based on Sharpe ratio\n",
    "    if sharpe > 1.0:  # Good performance\n",
    "        params['profit_weight'] = min(params['profit_weight'] * 1.05, 2.0)\n",
    "    elif sharpe < -0.5:  # Poor performance\n",
    "        params['profit_weight'] = max(params['profit_weight'] * 0.95, 0.5)\n",
    "    \n",
    "    logger.info(f\"Adapted reward parameters: profit_weight={params['profit_weight']:.3f}, \"\n",
    "                f\"drawdown_penalty={params['drawdown_penalty']:.3f}\")\n",
    "\n",
    "def _calculate_reward(\n",
    "                      position: float,\n",
    "                      drawdown: float,\n",
    "                      portfolio_value: float) -> float:\n",
    "        \"\"\"\n",
    "        Calculate custom composite reward.\n",
    "        \n",
    "        This combines multiple reward components for more sophisticated training.\n",
    "        \"\"\"\n",
    "        if previous_portfolio_value is None:\n",
    "            previous_portfolio_value = portfolio_value\n",
    "            return 0.0\n",
    "        \n",
    "        # Base profit reward\n",
    "        step_return = (portfolio_value - previous_portfolio_value) / previous_portfolio_value\n",
    "        profit_reward = step_return * params['profit_weight']\n",
    "        \n",
    "        # Custom reward components\n",
    "        custom_rewards = reward_config.get('custom_rewards', {})\n",
    "        custom_reward_total = 0.0\n",
    "        \n",
    "        # Trend following reward\n",
    "        if 'trend_following' in custom_rewards and len(returns_history) > 5:\n",
    "            recent_returns = returns_history[-5:]\n",
    "            trend_strength = np.mean(recent_returns)\n",
    "            position_alignment = np.sign(position) * np.sign(trend_strength)\n",
    "            trend_reward = position_alignment * abs(trend_strength) * custom_rewards['trend_following']\n",
    "            custom_reward_total += trend_reward\n",
    "        \n",
    "        # Mean reversion reward\n",
    "        if 'mean_reversion' in custom_rewards and len(returns_history) > 20:\n",
    "            recent_returns = np.array(returns_history[-20:])\n",
    "            z_score = (recent_returns[-1] - np.mean(recent_returns)) / (np.std(recent_returns) + 1e-8)\n",
    "            # Reward betting against extreme moves\n",
    "            mean_reversion_signal = -np.sign(z_score) if abs(z_score) > 1.5 else 0\n",
    "            position_alignment = np.sign(position) * mean_reversion_signal\n",
    "            mr_reward = position_alignment * custom_rewards['mean_reversion']\n",
    "            custom_reward_total += mr_reward\n",
    "        \n",
    "        # Volatility targeting reward\n",
    "        if 'volatility_targeting' in custom_rewards and len(returns_history) > 10:\n",
    "            recent_volatility = np.std(returns_history[-10:])\n",
    "            target_volatility = 0.02  # 2% daily volatility target\n",
    "            vol_adjustment = 1.0 - abs(recent_volatility - target_volatility) / target_volatility\n",
    "            vol_reward = vol_adjustment * custom_rewards['volatility_targeting']\n",
    "            custom_reward_total += vol_reward\n",
    "        \n",
    "        # Risk penalties\n",
    "        drawdown_penalty = drawdown * params['drawdown_penalty']\n",
    "        transaction_penalty = abs(position) * params['transaction_cost'] * params['penalty_weight']\n",
    "        \n",
    "        # Combine all components\n",
    "        total_reward = (profit_reward + custom_reward_total - \n",
    "                       drawdown_penalty - transaction_penalty)\n",
    "        \n",
    "        # Update tracking\n",
    "        previous_portfolio_value = portfolio_value\n",
    "        returns_history.append(step_return)\n",
    "        \n",
    "        if len(returns_history) > max_returns_history:\n",
    "            returns_history.pop(0)\n",
    "\n",
    "        _adapt_parameters()\n",
    "        \n",
    "        return float(total_reward)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c28b9882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-27 20:18:23.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[1mExtracting features from market data\u001b[0m\n",
      "\u001b[32m2025-08-27 20:18:23.704\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_add_technical_indicators\u001b[0m:\u001b[36m54\u001b[0m - \u001b[33m\u001b[1mFailed to calculate indicator sma_5: cannot access local variable 'min_periods' where it is not associated with a value\u001b[0m\n",
      "\u001b[32m2025-08-27 20:18:23.708\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_add_technical_indicators\u001b[0m:\u001b[36m54\u001b[0m - \u001b[33m\u001b[1mFailed to calculate indicator sma_20: cannot access local variable 'min_periods' where it is not associated with a value\u001b[0m\n",
      "\u001b[32m2025-08-27 20:18:23.712\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_add_technical_indicators\u001b[0m:\u001b[36m54\u001b[0m - \u001b[33m\u001b[1mFailed to calculate indicator sma_50: cannot access local variable 'min_periods' where it is not associated with a value\u001b[0m\n",
      "\u001b[32m2025-08-27 20:18:23.714\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_add_technical_indicators\u001b[0m:\u001b[36m54\u001b[0m - \u001b[33m\u001b[1mFailed to calculate indicator ema_12: cannot access local variable 'min_periods' where it is not associated with a value\u001b[0m\n",
      "\u001b[32m2025-08-27 20:18:23.717\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_add_technical_indicators\u001b[0m:\u001b[36m54\u001b[0m - \u001b[33m\u001b[1mFailed to calculate indicator ema_26: cannot access local variable 'min_periods' where it is not associated with a value\u001b[0m\n",
      "\u001b[32m2025-08-27 20:18:23.720\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_add_technical_indicators\u001b[0m:\u001b[36m54\u001b[0m - \u001b[33m\u001b[1mFailed to calculate indicator rsi_14: cannot access local variable 'min_periods' where it is not associated with a value\u001b[0m\n",
      "\u001b[32m2025-08-27 20:18:23.723\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_add_technical_indicators\u001b[0m:\u001b[36m54\u001b[0m - \u001b[33m\u001b[1mFailed to calculate indicator macd: cannot access local variable 'min_periods' where it is not associated with a value\u001b[0m\n",
      "\u001b[32m2025-08-27 20:18:23.726\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_add_technical_indicators\u001b[0m:\u001b[36m54\u001b[0m - \u001b[33m\u001b[1mFailed to calculate indicator macd_signal: cannot access local variable 'min_periods' where it is not associated with a value\u001b[0m\n",
      "\u001b[32m2025-08-27 20:18:23.729\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_add_technical_indicators\u001b[0m:\u001b[36m54\u001b[0m - \u001b[33m\u001b[1mFailed to calculate indicator bb_upper: cannot access local variable 'min_periods' where it is not associated with a value\u001b[0m\n",
      "\u001b[32m2025-08-27 20:18:23.732\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_add_technical_indicators\u001b[0m:\u001b[36m54\u001b[0m - \u001b[33m\u001b[1mFailed to calculate indicator bb_lower: cannot access local variable 'min_periods' where it is not associated with a value\u001b[0m\n",
      "\u001b[32m2025-08-27 20:18:23.733\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_add_technical_indicators\u001b[0m:\u001b[36m54\u001b[0m - \u001b[33m\u001b[1mFailed to calculate indicator atr_14: cannot access local variable 'min_periods' where it is not associated with a value\u001b[0m\n",
      "\u001b[32m2025-08-27 20:18:23.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m9\u001b[0m - \u001b[1mAdded Technical Indicator:                          open      high       low     close    volume  \\\n",
      "time                                                                    \n",
      "2023-08-28 19:00:00 -1.334567 -1.334879 -1.332644 -1.333872 -0.915339   \n",
      "2023-08-28 19:15:00 -1.333830 -1.334383 -1.331908 -1.332794 -0.871636   \n",
      "2023-08-28 19:30:00 -1.332746 -1.334474 -1.332118 -1.333509 -0.845035   \n",
      "2023-08-28 19:45:00 -1.333506 -1.335254 -1.332777 -1.334325 -0.822867   \n",
      "2023-08-28 20:00:00 -1.334245 -1.335086 -1.332321 -1.333675 -0.985010   \n",
      "...                       ...       ...       ...       ...       ...   \n",
      "2025-08-27 15:45:00  1.716620  1.711297  1.717232  1.714590 -0.278167   \n",
      "2025-08-27 16:00:00  1.714707  1.713125  1.719328  1.716733 -0.359238   \n",
      "2025-08-27 16:15:00  1.716840  1.716153  1.720644  1.721349 -0.340870   \n",
      "2025-08-27 16:30:00  1.721332  1.726075  1.724845  1.728351  0.225364   \n",
      "2025-08-27 16:45:00  1.728305  1.732009  1.732868  1.733403  0.134159   \n",
      "\n",
      "                     hour_of_day  day_of_week  is_weekend  hour_sin  hour_cos  \\\n",
      "time                                                                            \n",
      "2023-08-28 19:00:00     1.181694    -1.380295           0 -0.965926  0.258819   \n",
      "2023-08-28 19:15:00     1.181694    -1.380295           0 -0.965926  0.258819   \n",
      "2023-08-28 19:30:00     1.181694    -1.380295           0 -0.965926  0.258819   \n",
      "2023-08-28 19:45:00     1.181694    -1.380295           0 -0.965926  0.258819   \n",
      "2023-08-28 20:00:00     1.329964    -1.380295           0 -0.866025  0.500000   \n",
      "...                          ...          ...         ...       ...       ...   \n",
      "2025-08-27 15:45:00     0.588615    -0.018542           0 -0.707107 -0.707107   \n",
      "2025-08-27 16:00:00     0.736885    -0.018542           0 -0.866025 -0.500000   \n",
      "2025-08-27 16:15:00     0.736885    -0.018542           0 -0.866025 -0.500000   \n",
      "2025-08-27 16:30:00     0.736885    -0.018542           0 -0.866025 -0.500000   \n",
      "2025-08-27 16:45:00     0.736885    -0.018542           0 -0.866025 -0.500000   \n",
      "\n",
      "                      dow_sin   dow_cos  price_change  high_low_ratio  \\\n",
      "time                                                                    \n",
      "2023-08-28 19:00:00  0.000000  1.000000           NaN        1.001677   \n",
      "2023-08-28 19:15:00  0.000000  1.000000     -0.000808        1.001859   \n",
      "2023-08-28 19:30:00  0.000000  1.000000      0.000536        1.001769   \n",
      "2023-08-28 19:45:00  0.000000  1.000000      0.000612        1.001859   \n",
      "2023-08-28 20:00:00  0.000000  1.000000     -0.000487        1.002075   \n",
      "...                       ...       ...           ...             ...   \n",
      "2025-08-27 15:45:00  0.974928 -0.222521     -0.001176        0.996544   \n",
      "2025-08-27 16:00:00  0.974928 -0.222521      0.001250        0.996392   \n",
      "2025-08-27 16:15:00  0.974928 -0.222521      0.002689        0.997390   \n",
      "2025-08-27 16:30:00  0.974928 -0.222521      0.004068        1.000713   \n",
      "2025-08-27 16:45:00  0.974928 -0.222521      0.002923        0.999504   \n",
      "\n",
      "                     volume_ratio  volatility  price_position  volume_sma  \n",
      "time                                                                       \n",
      "2023-08-28 19:00:00           NaN         NaN        0.549625         NaN  \n",
      "2023-08-28 19:15:00           NaN         NaN        0.358244         NaN  \n",
      "2023-08-28 19:30:00           NaN    0.000950        0.590277         NaN  \n",
      "2023-08-28 19:45:00           NaN    0.000799        0.624857         NaN  \n",
      "2023-08-28 20:00:00           NaN    0.000718        0.489538         NaN  \n",
      "...                           ...         ...             ...         ...  \n",
      "2025-08-27 15:45:00     -4.238543    0.002416        0.445215    0.065628  \n",
      "2025-08-27 16:00:00     -6.074800    0.002413        0.418330    0.059136  \n",
      "2025-08-27 16:15:00     -5.610952    0.002373       -0.157091    0.060751  \n",
      "2025-08-27 16:30:00      2.577137    0.002444        2.851916    0.087448  \n",
      "2025-08-27 16:45:00      1.186205    0.002463       -0.622723    0.113099  \n",
      "\n",
      "[47224 rows x 18 columns]\u001b[0m\n",
      "\u001b[32m2025-08-27 20:18:24.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mAdded Time Features:                          open      high       low     close    volume  \\\n",
      "time                                                                    \n",
      "2023-08-28 19:00:00 -1.334567 -1.334879 -1.332644 -1.333872 -0.915339   \n",
      "2023-08-28 19:15:00 -1.333830 -1.334383 -1.331908 -1.332794 -0.871636   \n",
      "2023-08-28 19:30:00 -1.332746 -1.334474 -1.332118 -1.333509 -0.845035   \n",
      "2023-08-28 19:45:00 -1.333506 -1.335254 -1.332777 -1.334325 -0.822867   \n",
      "2023-08-28 20:00:00 -1.334245 -1.335086 -1.332321 -1.333675 -0.985010   \n",
      "...                       ...       ...       ...       ...       ...   \n",
      "2025-08-27 15:45:00  1.716620  1.711297  1.717232  1.714590 -0.278167   \n",
      "2025-08-27 16:00:00  1.714707  1.713125  1.719328  1.716733 -0.359238   \n",
      "2025-08-27 16:15:00  1.716840  1.716153  1.720644  1.721349 -0.340870   \n",
      "2025-08-27 16:30:00  1.721332  1.726075  1.724845  1.728351  0.225364   \n",
      "2025-08-27 16:45:00  1.728305  1.732009  1.732868  1.733403  0.134159   \n",
      "\n",
      "                     hour_of_day  day_of_week  is_weekend  hour_sin  hour_cos  \\\n",
      "time                                                                            \n",
      "2023-08-28 19:00:00           19            0           0 -0.965926  0.258819   \n",
      "2023-08-28 19:15:00           19            0           0 -0.965926  0.258819   \n",
      "2023-08-28 19:30:00           19            0           0 -0.965926  0.258819   \n",
      "2023-08-28 19:45:00           19            0           0 -0.965926  0.258819   \n",
      "2023-08-28 20:00:00           20            0           0 -0.866025  0.500000   \n",
      "...                          ...          ...         ...       ...       ...   \n",
      "2025-08-27 15:45:00           15            2           0 -0.707107 -0.707107   \n",
      "2025-08-27 16:00:00           16            2           0 -0.866025 -0.500000   \n",
      "2025-08-27 16:15:00           16            2           0 -0.866025 -0.500000   \n",
      "2025-08-27 16:30:00           16            2           0 -0.866025 -0.500000   \n",
      "2025-08-27 16:45:00           16            2           0 -0.866025 -0.500000   \n",
      "\n",
      "                      dow_sin   dow_cos  price_change  high_low_ratio  \\\n",
      "time                                                                    \n",
      "2023-08-28 19:00:00  0.000000  1.000000           NaN        1.001677   \n",
      "2023-08-28 19:15:00  0.000000  1.000000     -0.000808        1.001859   \n",
      "2023-08-28 19:30:00  0.000000  1.000000      0.000536        1.001769   \n",
      "2023-08-28 19:45:00  0.000000  1.000000      0.000612        1.001859   \n",
      "2023-08-28 20:00:00  0.000000  1.000000     -0.000487        1.002075   \n",
      "...                       ...       ...           ...             ...   \n",
      "2025-08-27 15:45:00  0.974928 -0.222521     -0.001176        0.996544   \n",
      "2025-08-27 16:00:00  0.974928 -0.222521      0.001250        0.996392   \n",
      "2025-08-27 16:15:00  0.974928 -0.222521      0.002689        0.997390   \n",
      "2025-08-27 16:30:00  0.974928 -0.222521      0.004068        1.000713   \n",
      "2025-08-27 16:45:00  0.974928 -0.222521      0.002923        0.999504   \n",
      "\n",
      "                     volume_ratio  volatility  price_position  volume_sma  \n",
      "time                                                                       \n",
      "2023-08-28 19:00:00           NaN         NaN        0.549625         NaN  \n",
      "2023-08-28 19:15:00           NaN         NaN        0.358244         NaN  \n",
      "2023-08-28 19:30:00           NaN    0.000950        0.590277         NaN  \n",
      "2023-08-28 19:45:00           NaN    0.000799        0.624857         NaN  \n",
      "2023-08-28 20:00:00           NaN    0.000718        0.489538         NaN  \n",
      "...                           ...         ...             ...         ...  \n",
      "2025-08-27 15:45:00     -4.238543    0.002416        0.445215    0.065628  \n",
      "2025-08-27 16:00:00     -6.074800    0.002413        0.418330    0.059136  \n",
      "2025-08-27 16:15:00     -5.610952    0.002373       -0.157091    0.060751  \n",
      "2025-08-27 16:30:00      2.577137    0.002444        2.851916    0.087448  \n",
      "2025-08-27 16:45:00      1.186205    0.002463       -0.622723    0.113099  \n",
      "\n",
      "[47224 rows x 18 columns]\u001b[0m\n",
      "\u001b[32m2025-08-27 20:18:24.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_normalize_features\u001b[0m:\u001b[36m149\u001b[0m - \u001b[1mFeature normalization parameters fitted for 13 features\u001b[0m\n",
      "\u001b[32m2025-08-27 20:18:24.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mNormalized Features:                          open      high       low     close    volume  \\\n",
      "time                                                                    \n",
      "2023-08-28 19:00:00 -1.334567 -1.334879 -1.332644 -1.333872 -0.915339   \n",
      "2023-08-28 19:15:00 -1.333830 -1.334383 -1.331908 -1.332794 -0.871636   \n",
      "2023-08-28 19:30:00 -1.332746 -1.334474 -1.332118 -1.333509 -0.845035   \n",
      "2023-08-28 19:45:00 -1.333506 -1.335254 -1.332777 -1.334325 -0.822867   \n",
      "2023-08-28 20:00:00 -1.334245 -1.335086 -1.332321 -1.333675 -0.985010   \n",
      "...                       ...       ...       ...       ...       ...   \n",
      "2025-08-27 15:45:00  1.716620  1.711297  1.717232  1.714590 -0.278167   \n",
      "2025-08-27 16:00:00  1.714707  1.713125  1.719328  1.716733 -0.359238   \n",
      "2025-08-27 16:15:00  1.716840  1.716153  1.720644  1.721349 -0.340870   \n",
      "2025-08-27 16:30:00  1.721332  1.726075  1.724845  1.728351  0.225364   \n",
      "2025-08-27 16:45:00  1.728305  1.732009  1.732868  1.733403  0.134159   \n",
      "\n",
      "                     hour_of_day  day_of_week  is_weekend  hour_sin  hour_cos  \\\n",
      "time                                                                            \n",
      "2023-08-28 19:00:00     1.181694    -1.380295           0 -0.965926  0.258819   \n",
      "2023-08-28 19:15:00     1.181694    -1.380295           0 -0.965926  0.258819   \n",
      "2023-08-28 19:30:00     1.181694    -1.380295           0 -0.965926  0.258819   \n",
      "2023-08-28 19:45:00     1.181694    -1.380295           0 -0.965926  0.258819   \n",
      "2023-08-28 20:00:00     1.329964    -1.380295           0 -0.866025  0.500000   \n",
      "...                          ...          ...         ...       ...       ...   \n",
      "2025-08-27 15:45:00     0.588615    -0.018542           0 -0.707107 -0.707107   \n",
      "2025-08-27 16:00:00     0.736885    -0.018542           0 -0.866025 -0.500000   \n",
      "2025-08-27 16:15:00     0.736885    -0.018542           0 -0.866025 -0.500000   \n",
      "2025-08-27 16:30:00     0.736885    -0.018542           0 -0.866025 -0.500000   \n",
      "2025-08-27 16:45:00     0.736885    -0.018542           0 -0.866025 -0.500000   \n",
      "\n",
      "                      dow_sin   dow_cos  price_change  high_low_ratio  \\\n",
      "time                                                                    \n",
      "2023-08-28 19:00:00  0.000000  1.000000           NaN        0.012867   \n",
      "2023-08-28 19:15:00  0.000000  1.000000      0.000032        0.014068   \n",
      "2023-08-28 19:30:00  0.000000  1.000000      0.001222        0.013476   \n",
      "2023-08-28 19:45:00  0.000000  1.000000      0.001290        0.014071   \n",
      "2023-08-28 20:00:00  0.000000  1.000000      0.000316        0.015504   \n",
      "...                       ...       ...           ...             ...   \n",
      "2025-08-27 15:45:00  0.974928 -0.222521     -0.000294       -0.021140   \n",
      "2025-08-27 16:00:00  0.974928 -0.222521      0.001855       -0.022146   \n",
      "2025-08-27 16:15:00  0.974928 -0.222521      0.003129       -0.015535   \n",
      "2025-08-27 16:30:00  0.974928 -0.222521      0.004351        0.006476   \n",
      "2025-08-27 16:45:00  0.974928 -0.222521      0.003337       -0.001531   \n",
      "\n",
      "                     volume_ratio  volatility  price_position  volume_sma  \n",
      "time                                                                       \n",
      "2023-08-28 19:00:00           NaN         NaN        0.001219         NaN  \n",
      "2023-08-28 19:15:00           NaN         NaN       -0.000417         NaN  \n",
      "2023-08-28 19:30:00           NaN   -0.040122        0.001567         NaN  \n",
      "2023-08-28 19:45:00           NaN   -0.040254        0.001863         NaN  \n",
      "2023-08-28 20:00:00           NaN   -0.040325        0.000706         NaN  \n",
      "...                           ...         ...             ...         ...  \n",
      "2025-08-27 15:45:00     -0.037119   -0.038839        0.000327    0.087119  \n",
      "2025-08-27 16:00:00     -0.050701   -0.038842        0.000097    0.078476  \n",
      "2025-08-27 16:15:00     -0.047270   -0.038876       -0.004823    0.080626  \n",
      "2025-08-27 16:30:00      0.013296   -0.038814        0.020903    0.116167  \n",
      "2025-08-27 16:45:00      0.003007   -0.038798       -0.008804    0.150317  \n",
      "\n",
      "[47224 rows x 18 columns]\u001b[0m\n",
      "\u001b[32m2025-08-27 20:18:24.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_select_features\u001b[0m:\u001b[36m247\u001b[0m - \u001b[1mSelected 17 features: ['open', 'high', 'low', 'close', 'volume', 'hour_of_day', 'day_of_week', 'is_weekend', 'hour_sin', 'hour_cos', 'dow_sin', 'dow_cos', 'price_change', 'high_low_ratio', 'volume_ratio', 'volatility', 'price_position']\u001b[0m\n",
      "\u001b[32m2025-08-27 20:18:24.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mSelected Features:                          open      high       low     close    volume  \\\n",
      "time                                                                    \n",
      "2023-08-28 19:00:00 -1.334567 -1.334879 -1.332644 -1.333872 -0.915339   \n",
      "2023-08-28 19:15:00 -1.333830 -1.334383 -1.331908 -1.332794 -0.871636   \n",
      "2023-08-28 19:30:00 -1.332746 -1.334474 -1.332118 -1.333509 -0.845035   \n",
      "2023-08-28 19:45:00 -1.333506 -1.335254 -1.332777 -1.334325 -0.822867   \n",
      "2023-08-28 20:00:00 -1.334245 -1.335086 -1.332321 -1.333675 -0.985010   \n",
      "...                       ...       ...       ...       ...       ...   \n",
      "2025-08-27 15:45:00  1.716620  1.711297  1.717232  1.714590 -0.278167   \n",
      "2025-08-27 16:00:00  1.714707  1.713125  1.719328  1.716733 -0.359238   \n",
      "2025-08-27 16:15:00  1.716840  1.716153  1.720644  1.721349 -0.340870   \n",
      "2025-08-27 16:30:00  1.721332  1.726075  1.724845  1.728351  0.225364   \n",
      "2025-08-27 16:45:00  1.728305  1.732009  1.732868  1.733403  0.134159   \n",
      "\n",
      "                     hour_of_day  day_of_week  is_weekend  hour_sin  hour_cos  \\\n",
      "time                                                                            \n",
      "2023-08-28 19:00:00     1.181694    -1.380295           0 -0.965926  0.258819   \n",
      "2023-08-28 19:15:00     1.181694    -1.380295           0 -0.965926  0.258819   \n",
      "2023-08-28 19:30:00     1.181694    -1.380295           0 -0.965926  0.258819   \n",
      "2023-08-28 19:45:00     1.181694    -1.380295           0 -0.965926  0.258819   \n",
      "2023-08-28 20:00:00     1.329964    -1.380295           0 -0.866025  0.500000   \n",
      "...                          ...          ...         ...       ...       ...   \n",
      "2025-08-27 15:45:00     0.588615    -0.018542           0 -0.707107 -0.707107   \n",
      "2025-08-27 16:00:00     0.736885    -0.018542           0 -0.866025 -0.500000   \n",
      "2025-08-27 16:15:00     0.736885    -0.018542           0 -0.866025 -0.500000   \n",
      "2025-08-27 16:30:00     0.736885    -0.018542           0 -0.866025 -0.500000   \n",
      "2025-08-27 16:45:00     0.736885    -0.018542           0 -0.866025 -0.500000   \n",
      "\n",
      "                      dow_sin   dow_cos  price_change  high_low_ratio  \\\n",
      "time                                                                    \n",
      "2023-08-28 19:00:00  0.000000  1.000000           NaN        0.012867   \n",
      "2023-08-28 19:15:00  0.000000  1.000000      0.000032        0.014068   \n",
      "2023-08-28 19:30:00  0.000000  1.000000      0.001222        0.013476   \n",
      "2023-08-28 19:45:00  0.000000  1.000000      0.001290        0.014071   \n",
      "2023-08-28 20:00:00  0.000000  1.000000      0.000316        0.015504   \n",
      "...                       ...       ...           ...             ...   \n",
      "2025-08-27 15:45:00  0.974928 -0.222521     -0.000294       -0.021140   \n",
      "2025-08-27 16:00:00  0.974928 -0.222521      0.001855       -0.022146   \n",
      "2025-08-27 16:15:00  0.974928 -0.222521      0.003129       -0.015535   \n",
      "2025-08-27 16:30:00  0.974928 -0.222521      0.004351        0.006476   \n",
      "2025-08-27 16:45:00  0.974928 -0.222521      0.003337       -0.001531   \n",
      "\n",
      "                     volume_ratio  volatility  price_position  \n",
      "time                                                           \n",
      "2023-08-28 19:00:00           NaN         NaN        0.001219  \n",
      "2023-08-28 19:15:00           NaN         NaN       -0.000417  \n",
      "2023-08-28 19:30:00           NaN   -0.040122        0.001567  \n",
      "2023-08-28 19:45:00           NaN   -0.040254        0.001863  \n",
      "2023-08-28 20:00:00           NaN   -0.040325        0.000706  \n",
      "...                           ...         ...             ...  \n",
      "2025-08-27 15:45:00     -0.037119   -0.038839        0.000327  \n",
      "2025-08-27 16:00:00     -0.050701   -0.038842        0.000097  \n",
      "2025-08-27 16:15:00     -0.047270   -0.038876       -0.004823  \n",
      "2025-08-27 16:30:00      0.013296   -0.038814        0.020903  \n",
      "2025-08-27 16:45:00      0.003007   -0.038798       -0.008804  \n",
      "\n",
      "[47224 rows x 17 columns]\u001b[0m\n",
      "\u001b[32m2025-08-27 20:18:24.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1mHandled NaN Values:                          open      high       low     close    volume  \\\n",
      "time                                                                    \n",
      "2023-08-28 19:00:00 -1.334567 -1.334879 -1.332644 -1.333872 -0.915339   \n",
      "2023-08-28 19:15:00 -1.333830 -1.334383 -1.331908 -1.332794 -0.871636   \n",
      "2023-08-28 19:30:00 -1.332746 -1.334474 -1.332118 -1.333509 -0.845035   \n",
      "2023-08-28 19:45:00 -1.333506 -1.335254 -1.332777 -1.334325 -0.822867   \n",
      "2023-08-28 20:00:00 -1.334245 -1.335086 -1.332321 -1.333675 -0.985010   \n",
      "...                       ...       ...       ...       ...       ...   \n",
      "2025-08-27 15:45:00  1.716620  1.711297  1.717232  1.714590 -0.278167   \n",
      "2025-08-27 16:00:00  1.714707  1.713125  1.719328  1.716733 -0.359238   \n",
      "2025-08-27 16:15:00  1.716840  1.716153  1.720644  1.721349 -0.340870   \n",
      "2025-08-27 16:30:00  1.721332  1.726075  1.724845  1.728351  0.225364   \n",
      "2025-08-27 16:45:00  1.728305  1.732009  1.732868  1.733403  0.134159   \n",
      "\n",
      "                     hour_of_day  day_of_week  is_weekend  hour_sin  hour_cos  \\\n",
      "time                                                                            \n",
      "2023-08-28 19:00:00     1.181694    -1.380295           0 -0.965926  0.258819   \n",
      "2023-08-28 19:15:00     1.181694    -1.380295           0 -0.965926  0.258819   \n",
      "2023-08-28 19:30:00     1.181694    -1.380295           0 -0.965926  0.258819   \n",
      "2023-08-28 19:45:00     1.181694    -1.380295           0 -0.965926  0.258819   \n",
      "2023-08-28 20:00:00     1.329964    -1.380295           0 -0.866025  0.500000   \n",
      "...                          ...          ...         ...       ...       ...   \n",
      "2025-08-27 15:45:00     0.588615    -0.018542           0 -0.707107 -0.707107   \n",
      "2025-08-27 16:00:00     0.736885    -0.018542           0 -0.866025 -0.500000   \n",
      "2025-08-27 16:15:00     0.736885    -0.018542           0 -0.866025 -0.500000   \n",
      "2025-08-27 16:30:00     0.736885    -0.018542           0 -0.866025 -0.500000   \n",
      "2025-08-27 16:45:00     0.736885    -0.018542           0 -0.866025 -0.500000   \n",
      "\n",
      "                      dow_sin   dow_cos  price_change  high_low_ratio  \\\n",
      "time                                                                    \n",
      "2023-08-28 19:00:00  0.000000  1.000000  4.890125e-19        0.012867   \n",
      "2023-08-28 19:15:00  0.000000  1.000000  3.202571e-05        0.014068   \n",
      "2023-08-28 19:30:00  0.000000  1.000000  1.222380e-03        0.013476   \n",
      "2023-08-28 19:45:00  0.000000  1.000000  1.289709e-03        0.014071   \n",
      "2023-08-28 20:00:00  0.000000  1.000000  3.162208e-04        0.015504   \n",
      "...                       ...       ...           ...             ...   \n",
      "2025-08-27 15:45:00  0.974928 -0.222521 -2.937786e-04       -0.021140   \n",
      "2025-08-27 16:00:00  0.974928 -0.222521  1.854693e-03       -0.022146   \n",
      "2025-08-27 16:15:00  0.974928 -0.222521  3.129306e-03       -0.015535   \n",
      "2025-08-27 16:30:00  0.974928 -0.222521  4.350615e-03        0.006476   \n",
      "2025-08-27 16:45:00  0.974928 -0.222521  3.336770e-03       -0.001531   \n",
      "\n",
      "                     volume_ratio    volatility  price_position  \n",
      "time                                                             \n",
      "2023-08-28 19:00:00  1.806273e-18  9.629989e-18        0.001219  \n",
      "2023-08-28 19:15:00  1.806273e-18  9.629989e-18       -0.000417  \n",
      "2023-08-28 19:30:00  1.806273e-18 -4.012183e-02        0.001567  \n",
      "2023-08-28 19:45:00  1.806273e-18 -4.025449e-02        0.001863  \n",
      "2023-08-28 20:00:00  1.806273e-18 -4.032522e-02        0.000706  \n",
      "...                           ...           ...             ...  \n",
      "2025-08-27 15:45:00 -3.711854e-02 -3.883904e-02        0.000327  \n",
      "2025-08-27 16:00:00 -5.070102e-02 -3.884177e-02        0.000097  \n",
      "2025-08-27 16:15:00 -4.727002e-02 -3.887621e-02       -0.004823  \n",
      "2025-08-27 16:30:00  1.329588e-02 -3.881404e-02        0.020903  \n",
      "2025-08-27 16:45:00  3.007390e-03 -3.879752e-02       -0.008804  \n",
      "\n",
      "[47224 rows x 17 columns]\u001b[0m\n",
      "\u001b[32m2025-08-27 20:18:24.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mFeature extraction complete. Shape: (47224, 17)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Extracting features from market data\")\n",
    "        \n",
    "# Validate input data first\n",
    "if not _validate_input_data(data):\n",
    "    logger.error(\"Invalid input data for feature extraction\")\n",
    "\n",
    "# Add technical indicators with NaN handling\n",
    "data = _add_technical_indicators(data)\n",
    "logger.info(f\"Added Technical Indicator: {data}\")\n",
    "\n",
    "# Add time features\n",
    "data = _add_time_features(data)\n",
    "logger.info(f\"Added Time Features: {data}\")\n",
    "\n",
    "# Normalize features\n",
    "data = _normalize_features(data, is_fitted)\n",
    "logger.info(f\"Normalized Features: {data}\")\n",
    "\n",
    "# Select only the configured features\n",
    "data = _select_features(data)\n",
    "logger.info(f\"Selected Features: {data}\")\n",
    "\n",
    "# Handle any remaining NaN values\n",
    "data = _handle_nan_values(data)\n",
    "logger.info(f\"Handled NaN Values: {data}\")\n",
    "\n",
    "logger.info(f\"Feature extraction complete. Shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302ac563",
   "metadata": {},
   "source": [
    "Create training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107ff694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-27 22:56:11.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_setup_spaces\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mAction space: Discrete(3)\u001b[0m\n",
      "\u001b[32m2025-08-27 22:56:11.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_setup_spaces\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mObservation space: (1705,)\u001b[0m\n",
      "\u001b[32m2025-08-27 22:56:11.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m174\u001b[0m - \u001b[1mTrading environment initialized with 47224 data points\u001b[0m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0ea9542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trading_env_init(\n",
    "    data: pd.DataFrame,\n",
    "    config_path: str = \"config/model_config.yaml\",\n",
    "    initial_balance: float = 10_000.0,\n",
    "    transaction_cost: float = 0.0001,\n",
    "    render_mode: Optional[str] = None,\n",
    "    expected_signature: Optional[Dict[str, Any]] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Initialize a trading environment state dictionary.\n",
    "    \n",
    "    Returns a state dictionary that contains all environment parameters and state.\n",
    "    \"\"\"\n",
    "    # Load main config\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "    # Create state dictionary\n",
    "    state = {\n",
    "        \"config\": config,\n",
    "        \"raw_data\": data.copy() if data is not None else pd.DataFrame(),\n",
    "        \"initial_balance\": float(initial_balance),\n",
    "        \"transaction_cost\": float(transaction_cost),\n",
    "        \"render_mode\": render_mode,\n",
    "        \"_expected_signature\": expected_signature,\n",
    "    }\n",
    "\n",
    "    # Environment params from config as defaults\n",
    "    env_cfg = config.get(\"environment\", {})\n",
    "    state[\"action_config\"] = env_cfg.get(\"action_space\", {\"type\": \"discrete\", \"actions\": [\"hold\", \"buy\", \"sell\"]})\n",
    "    state[\"reward_config\"] = env_cfg.get(\"reward_function\", {})\n",
    "    \n",
    "    # Backtest config\n",
    "    state[\"backtest_cfg\"] = config.get(\"backtesting\", {})\n",
    "\n",
    "    # Load persisted observation signature if present\n",
    "    obs_config_path = Path(\"models/saved_models/obs_config.yaml\")\n",
    "    if obs_config_path.exists():\n",
    "        with open(obs_config_path, \"r\") as f:\n",
    "            obs_config = yaml.safe_load(f) or {}\n",
    "    else:\n",
    "        obs_config = {}\n",
    "\n",
    "    # Persistent observation params, fall back to config-derived defaults\n",
    "    state[\"feature_names\"] = obs_config.get(\"feature_names\", [])\n",
    "    state[\"n_features\"] = int(obs_config.get(\"n_features\", len(state[\"feature_names\"]))) if obs_config else 0\n",
    "    state[\"lookback_window\"] = int(obs_config.get(\"lookback_window\", env_cfg.get(\"lookback_window\", 100)))\n",
    "    state[\"portfolio_features_dim\"] = int(obs_config.get(\"portfolio_features_dim\", 5))\n",
    "    \n",
    "    # Compute obs_dim if present, otherwise compute from lookback and n_features\n",
    "    state[\"obs_dim\"] = int(obs_config.get(\"obs_dim\", \n",
    "        state[\"lookback_window\"] * max(1, state[\"n_features\"]) + state[\"portfolio_features_dim\"]))\n",
    "\n",
    "    # Prepare data and validate against obs_config when available\n",
    "    state = _prepare_data(state)\n",
    "\n",
    "    # If feature names were not provided by obs_config, derive them now\n",
    "    if not state[\"feature_names\"]:\n",
    "        state[\"feature_names\"] = list(state[\"processed_data\"].columns)\n",
    "        state[\"n_features\"] = int(len(state[\"feature_names\"]))\n",
    "        state[\"obs_dim\"] = int(state[\"lookback_window\"] * state[\"n_features\"] + state[\"portfolio_features_dim\"])\n",
    "\n",
    "    # Validate observation signature consistency\n",
    "    expected_obs_dim = state[\"lookback_window\"] * state[\"n_features\"] + state[\"portfolio_features_dim\"]\n",
    "    if state[\"obs_dim\"] != expected_obs_dim:\n",
    "        logger.warning(f\"Observation dimension mismatch: config={state['obs_dim']}, calculated={expected_obs_dim}\")\n",
    "        state[\"obs_dim\"] = expected_obs_dim\n",
    "\n",
    "    # Build action and observation spaces\n",
    "    state = _setup_spaces(state)\n",
    "\n",
    "    # Reset internal state\n",
    "    state = trading_env_reset(state)\n",
    "\n",
    "    logger.info(f\"Trading environment initialized with {len(state['raw_data'])} data points\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def trading_env_obs_signature(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Get observation signature from environment state.\"\"\"\n",
    "    return {\n",
    "        \"lookback_window\": int(state[\"lookback_window\"]),\n",
    "        \"n_features\": int(state[\"n_features\"]),\n",
    "        \"feature_names\": list(state[\"feature_names\"]),\n",
    "        \"portfolio_features_dim\": int(state[\"portfolio_features_dim\"]),\n",
    "        \"obs_dim\": int(state[\"obs_dim\"])\n",
    "    }\n",
    "\n",
    "def _prepare_data(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Prepare and validate data for the trading environment.\"\"\"\n",
    "    required_columns = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "    if not isinstance(state[\"raw_data\"], pd.DataFrame):\n",
    "        raise ValueError(\"data must be a pandas DataFrame\")\n",
    "\n",
    "    missing = [c for c in required_columns if c not in state[\"raw_data\"].columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Data must contain columns: {required_columns}. Missing: {missing}\")\n",
    "\n",
    "    # Extract features (in a real implementation, this would be more complex)\n",
    "    state[\"processed_data\"] = state[\"raw_data\"]\n",
    "\n",
    "    # Drop NaNs from indicator warmup\n",
    "    state[\"processed_data\"] = state[\"processed_data\"].dropna(axis=0, how=\"any\").reset_index(drop=True)\n",
    "\n",
    "    if len(state[\"processed_data\"]) < state[\"lookback_window\"]:\n",
    "        raise ValueError(f\"Insufficient data after feature extraction: need at least lookback_window ({state['lookback_window']}) rows, got {len(state['processed_data'])}\")\n",
    "\n",
    "    # If obs_config provided feature_names, ensure processed_data contains them\n",
    "    if state[\"feature_names\"]:\n",
    "        missing_feats = [f for f in state[\"feature_names\"] if f not in state[\"processed_data\"].columns]\n",
    "\n",
    "        if missing_feats:\n",
    "            logger.warning(f\"Processed data missing features required by obs_config.yaml: {missing_feats}\")\n",
    "            # Use available features instead of failing\n",
    "            available_features = [f for f in state[\"feature_names\"] if f in state[\"processed_data\"].columns]\n",
    "            if len(available_features) < len(state[\"feature_names\"]) * 0.8:  # If less than 80% features available\n",
    "                raise ValueError(f\"Too many missing features. Available: {len(available_features)}, Required: {len(state['feature_names'])}\")\n",
    "            \n",
    "            logger.info(f\"Using {len(available_features)} available features out of {len(state['feature_names'])} expected\")\n",
    "            state[\"feature_names\"] = available_features\n",
    "            \n",
    "        # Ensure n_features matches\n",
    "        state[\"n_features\"] = int(len(state[\"feature_names\"]))\n",
    "    else:\n",
    "        # Derive feature names from processed_data\n",
    "        state[\"feature_names\"] = list(state[\"processed_data\"].columns)\n",
    "        state[\"n_features\"] = int(len(state[\"feature_names\"]))\n",
    "\n",
    "    # Recompute obs_dim from final values\n",
    "    state[\"obs_dim\"] = int(state[\"lookback_window\"] * state[\"n_features\"] + state[\"portfolio_features_dim\"])\n",
    "\n",
    "    # Validate against expected signature if supplied\n",
    "    if state[\"_expected_signature\"]:\n",
    "        expected_obs_dim = int(state[\"_expected_signature\"].get(\"obs_dim\", -1))\n",
    "        expected_n_features = int(state[\"_expected_signature\"].get(\"n_features\", -1))\n",
    "        expected_lookback = int(state[\"_expected_signature\"].get(\"lookback_window\", -1))\n",
    "        \n",
    "        logger.info(f\"Validating against expected signature:\")\n",
    "        logger.info(f\"  Expected obs_dim: {expected_obs_dim}, Current: {state['obs_dim']}\")\n",
    "        logger.info(f\"  Expected n_features: {expected_n_features}, Current: {state['n_features']}\")\n",
    "        logger.info(f\"  Expected lookback: {expected_lookback}, Current: {state['lookback_window']}\")\n",
    "        \n",
    "        if int(state[\"_expected_signature\"].get(\"obs_dim\", -1)) != int(state[\"obs_dim\"]):\n",
    "            # Try to adjust to match expected signature\n",
    "            expected_obs_dim = int(state[\"_expected_signature\"].get(\"obs_dim\", -1))\n",
    "            expected_n_features = int(state[\"_expected_signature\"].get(\"n_features\", -1))\n",
    "            expected_lookback = int(state[\"_expected_signature\"].get(\"lookback_window\", -1))\n",
    "            \n",
    "            if expected_lookback > 0 and expected_n_features > 0:\n",
    "                logger.warning(f\"Adjusting environment to match expected signature\")\n",
    "                state[\"lookback_window\"] = expected_lookback\n",
    "                \n",
    "                # If we have more features than expected, select the first N\n",
    "                if state[\"n_features\"] > expected_n_features:\n",
    "                    expected_feature_names = state[\"_expected_signature\"].get(\"feature_names\", [])\n",
    "                    if expected_feature_names:\n",
    "                        # Use expected feature names if available\n",
    "                        available_expected = [f for f in expected_feature_names if f in state[\"processed_data\"].columns]\n",
    "                        if len(available_expected) >= expected_n_features:\n",
    "                            state[\"feature_names\"] = available_expected[:expected_n_features]\n",
    "                        else:\n",
    "                            # Fallback to first N features\n",
    "                            state[\"feature_names\"] = state[\"feature_names\"][:expected_n_features]\n",
    "                    else:\n",
    "                        state[\"feature_names\"] = state[\"feature_names\"][:expected_n_features]\n",
    "                    \n",
    "                    state[\"n_features\"] = len(state[\"feature_names\"])\n",
    "                \n",
    "                # Recalculate obs_dim\n",
    "                state[\"obs_dim\"] = int(state[\"lookback_window\"] * state[\"n_features\"] + state[\"portfolio_features_dim\"])\n",
    "                \n",
    "                logger.info(f\"Adjusted to: obs_dim={state['obs_dim']}, n_features={state['n_features']}, lookback={state['lookback_window']}\")\n",
    "                \n",
    "                if state[\"obs_dim\"] != expected_obs_dim:\n",
    "                    raise ValueError(\n",
    "                        f\"Cannot adjust environment to match expected signature. \"\n",
    "                        f\"Expected obs_dim={expected_obs_dim}, achieved obs_dim={state['obs_dim']}\"\n",
    "                    )\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Observation signature mismatch. Expected obs_dim={expected_obs_dim}, \"\n",
    "                    f\"but environment produces obs_dim={state['obs_dim']}\"\n",
    "                )\n",
    "\n",
    "    logger.info(f\"Data prepared: {len(state['processed_data'])} samples, {len(state['processed_data'].columns)} features\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def _setup_spaces(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Set up action and observation spaces.\"\"\"\n",
    "    # Action space\n",
    "    if state[\"action_config\"].get(\"type\", \"discrete\") == \"discrete\":\n",
    "        actions = list(state[\"action_config\"].get(\"actions\", [\"hold\", \"buy\", \"sell\"]))\n",
    "        state[\"action_space\"] = spaces.Discrete(len(actions))\n",
    "    else:\n",
    "        bounds = state[\"action_config\"].get(\"continuous_bounds\", {\"position_size\": [-1.0, 1.0]})\n",
    "        low = float(bounds[\"position_size\"][0])\n",
    "        high = float(bounds[\"position_size\"][1])\n",
    "        state[\"action_space\"] = spaces.Box(\n",
    "            low=np.array([low], dtype=np.float32),\n",
    "            high=np.array([high], dtype=np.float32),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "    # Observation space\n",
    "    obs_dim = int(state[\"lookback_window\"] * state[\"n_features\"] + state[\"portfolio_features_dim\"])\n",
    "    state[\"obs_dim\"] = obs_dim\n",
    "    state[\"observation_space\"] = spaces.Box(\n",
    "        low=-np.inf,\n",
    "        high=np.inf,\n",
    "        shape=(obs_dim,),\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Action space: {state['action_space']}\")\n",
    "    logger.info(f\"Observation space: {state['observation_space'].shape}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def trading_env_reset(state: Dict[str, Any], seed: Optional[int] = None, options: Optional[Dict] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Reset the trading environment state.\"\"\"\n",
    "    # Reset internal state\n",
    "    state[\"current_step\"] = int(state[\"lookback_window\"])\n",
    "    state[\"balance\"] = float(state[\"initial_balance\"])\n",
    "    state[\"position\"] = 0.0\n",
    "    state[\"position_entry_price\"] = 0.0\n",
    "    state[\"total_trades\"] = 0\n",
    "    state[\"winning_trades\"] = 0\n",
    "    state[\"trade_history\"] = []\n",
    "    state[\"portfolio_values\"] = [state[\"initial_balance\"]]\n",
    "    state[\"unrealized_pnl\"] = 0.0\n",
    "\n",
    "    state[\"max_portfolio_value\"] = state[\"initial_balance\"]\n",
    "    state[\"current_drawdown\"] = 0.0\n",
    "    state[\"max_drawdown\"] = 0.0\n",
    "    \n",
    "    return state\n",
    "\n",
    "def trading_env_step(state: Dict[str, Any], action: Any) -> Tuple[Dict[str, Any], np.ndarray, float, bool, bool, Dict[str, Any]]:\n",
    "    \"\"\"Take a step in the trading environment.\"\"\"\n",
    "    state = _execute_action(state, action)\n",
    "    state[\"current_step\"] += 1\n",
    "\n",
    "    reward = _calculate_reward(\n",
    "        position=state[\"position\"],\n",
    "        drawdown=state[\"current_drawdown\"],\n",
    "        portfolio_value=_get_portfolio_value(state)\n",
    "    )\n",
    "\n",
    "    state = _update_portfolio_tracking(state)\n",
    "\n",
    "    terminated = (state[\"current_step\"] >= (len(state[\"processed_data\"]) - 1))\n",
    "    truncated = _check_early_termination(state)\n",
    "\n",
    "    obs = _get_observation(state)\n",
    "    info = _get_info(state)\n",
    "    \n",
    "    return state, obs, float(reward), bool(terminated), bool(truncated), info\n",
    "\n",
    "def _execute_action(state: Dict[str, Any], action: Any) -> Dict[str, Any]:\n",
    "    \"\"\"Execute a trading action.\"\"\"\n",
    "    current_price = _get_current_price(state)\n",
    "\n",
    "    if state[\"action_config\"].get(\"type\", \"discrete\") == \"discrete\":\n",
    "        if not isinstance(action, (int, np.integer)):\n",
    "            if isinstance(action, (list, tuple, np.ndarray)):\n",
    "                action = int(np.asarray(action).flatten()[0])\n",
    "            else:\n",
    "                action = int(action)\n",
    "\n",
    "        actions = state[\"action_config\"].get(\"actions\", [\"hold\", \"buy\", \"sell\"])\n",
    "        idx = int(action) % len(actions)\n",
    "        action_name = actions[idx]\n",
    "\n",
    "        if action_name == \"buy\" and state[\"position\"] <= 0:\n",
    "            state = _open_position(state, 1.0, current_price)\n",
    "        elif action_name == \"sell\" and state[\"position\"] >= 0:\n",
    "            state = _open_position(state, -1.0, current_price)\n",
    "        elif action_name == \"hold\":\n",
    "            if state[\"position\"] != 0.0:\n",
    "                state[\"unrealized_pnl\"] = (current_price - state[\"position_entry_price\"]) * state[\"position\"]\n",
    "    else:\n",
    "        if isinstance(action, (list, tuple, np.ndarray)):\n",
    "            target_position = float(np.asarray(action).flatten()[0])\n",
    "        else:\n",
    "            target_position = float(action)\n",
    "        if not math.isfinite(target_position):\n",
    "            return state\n",
    "        if target_position != state[\"position\"]:\n",
    "            state = _adjust_position(state, target_position, current_price)\n",
    "    \n",
    "    return state\n",
    "\n",
    "def _open_position(state: Dict[str, Any], direction: float, price: float) -> Dict[str, Any]:\n",
    "    \"\"\"Open a new position.\"\"\"\n",
    "    if state[\"position\"] != 0.0:\n",
    "        state = _close_position(state, price)\n",
    "\n",
    "    sizing = state[\"backtest_cfg\"].get(\"position_sizing\", {\"method\": \"fixed_fraction\", \"fraction\": 0.01, \"max_position\": 0.1})\n",
    "\n",
    "    if sizing.get(\"method\", \"fixed_fraction\") == \"fixed_fraction\":\n",
    "        fraction = float(sizing.get(\"fraction\", 0.01))\n",
    "        position_value = state[\"balance\"] * fraction\n",
    "        position_size = (position_value / price) * float(direction)\n",
    "    elif sizing.get(\"method\") == \"fixed\":\n",
    "        position_size = float(sizing.get(\"size\", 0.01)) * float(direction)\n",
    "    else:\n",
    "        position_size = 0.01 * float(direction)\n",
    "\n",
    "    max_pos = float(sizing.get(\"max_position\", 0.1))\n",
    "    max_pos_val = state[\"balance\"] * max_pos\n",
    "    max_pos_size = max_pos_val / price if price > 0 else max_pos_val\n",
    "    if abs(position_size) > max_pos_size:\n",
    "        position_size = math.copysign(max_pos_size, position_size)\n",
    "\n",
    "    trade_cost = abs(position_size) * price * state[\"transaction_cost\"]\n",
    "\n",
    "    if state[\"balance\"] >= trade_cost:\n",
    "        state[\"position\"] = float(position_size)\n",
    "        state[\"position_entry_price\"] = float(price)\n",
    "        state[\"balance\"] -= float(trade_cost)\n",
    "        state[\"total_trades\"] += 1\n",
    "        state[\"unrealized_pnl\"] = 0.0\n",
    "\n",
    "        state[\"trade_history\"].append({\n",
    "            \"step\": state[\"current_step\"],\n",
    "            \"action\": \"BUY\" if direction > 0 else \"SELL\",\n",
    "            \"size\": state[\"position\"],\n",
    "            \"price\": price,\n",
    "            \"cost\": trade_cost,\n",
    "            \"balance_after\": state[\"balance\"]\n",
    "        })\n",
    "    \n",
    "    return state\n",
    "\n",
    "def _close_position(state: Dict[str, Any], price: float) -> Dict[str, Any]:\n",
    "    \"\"\"Close the current position.\"\"\"\n",
    "    if state[\"position\"] == 0.0:\n",
    "        return state\n",
    "\n",
    "    pnl = (price - state[\"position_entry_price\"]) * state[\"position\"]\n",
    "    trade_cost = abs(state[\"position\"]) * price * state[\"transaction_cost\"]\n",
    "    net_pnl = pnl - trade_cost\n",
    "\n",
    "    state[\"balance\"] += state[\"position\"] * price + net_pnl\n",
    "\n",
    "    if net_pnl > 0:\n",
    "        state[\"winning_trades\"] += 1\n",
    "\n",
    "    state[\"trade_history\"].append({\n",
    "        \"step\": state[\"current_step\"],\n",
    "        \"action\": \"CLOSE\",\n",
    "        \"size\": state[\"position\"],\n",
    "        \"entry_price\": state[\"position_entry_price\"],\n",
    "        \"exit_price\": price,\n",
    "        \"pnl\": net_pnl,\n",
    "        \"balance_after\": state[\"balance\"]\n",
    "    })\n",
    "\n",
    "    state[\"position\"] = 0.0\n",
    "    state[\"position_entry_price\"] = 0.0\n",
    "    state[\"unrealized_pnl\"] = 0.0\n",
    "    \n",
    "    return state\n",
    "\n",
    "def _adjust_position(state: Dict[str, Any], target_position: float, price: float) -> Dict[str, Any]:\n",
    "    \"\"\"Adjust the current position to a target position.\"\"\"\n",
    "    if target_position == state[\"position\"]:\n",
    "        return state\n",
    "\n",
    "    delta = target_position - state[\"position\"]\n",
    "    trade_cost = abs(delta) * price * state[\"transaction_cost\"]\n",
    "    if state[\"balance\"] >= trade_cost:\n",
    "        if state[\"position\"] == 0.0 and target_position != 0.0:\n",
    "            state[\"position_entry_price\"] = price\n",
    "        elif state[\"position\"] != 0.0 and target_position != 0.0:\n",
    "            prev_val = state[\"position\"] * state[\"position_entry_price\"]\n",
    "            added_val = delta * price\n",
    "            new_pos = state[\"position\"] + delta\n",
    "            if new_pos != 0:\n",
    "                state[\"position_entry_price\"] = (prev_val + added_val) / new_pos\n",
    "            else:\n",
    "                state[\"position_entry_price\"] = 0.0\n",
    "\n",
    "        state[\"position\"] = float(target_position)\n",
    "        state[\"balance\"] -= float(trade_cost)\n",
    "        state[\"total_trades\"] += 1\n",
    "    \n",
    "    return state\n",
    "\n",
    "def _get_current_price(state: Dict[str, Any]) -> float:\n",
    "    \"\"\"Get the current price from processed data.\"\"\"\n",
    "    try:\n",
    "        return float(state[\"processed_data\"].iloc[state[\"current_step\"]][\"close\"])\n",
    "    except Exception:\n",
    "        return float(state[\"processed_data\"].iloc[state[\"current_step\"]].iloc[-1])\n",
    "\n",
    "def _get_portfolio_value(state: Dict[str, Any]) -> float:\n",
    "    \"\"\"Calculate the current portfolio value.\"\"\"\n",
    "    current_price = _get_current_price(state)\n",
    "    position_value = state[\"position\"] * current_price if state[\"position\"] != 0.0 else 0.0\n",
    "    return float(state[\"balance\"] + position_value)\n",
    "\n",
    "def _update_portfolio_tracking(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Update portfolio tracking metrics.\"\"\"\n",
    "    pv = _get_portfolio_value(state)\n",
    "    state[\"portfolio_values\"].append(pv)\n",
    "\n",
    "    if pv > state[\"max_portfolio_value\"]:\n",
    "        state[\"max_portfolio_value\"] = pv\n",
    "\n",
    "    if state[\"max_portfolio_value\"] > 0:\n",
    "        state[\"current_drawdown\"] = (state[\"max_portfolio_value\"] - pv) / float(state[\"max_portfolio_value\"])\n",
    "    else:\n",
    "        state[\"current_drawdown\"] = 0.0\n",
    "\n",
    "    if state[\"current_drawdown\"] > state[\"max_drawdown\"]:\n",
    "        state[\"max_drawdown\"] = state[\"current_drawdown\"]\n",
    "    \n",
    "    return state\n",
    "\n",
    "def _check_early_termination(state: Dict[str, Any]) -> bool:\n",
    "    \"\"\"Check if early termination conditions are met.\"\"\"\n",
    "    risk_cfg = state[\"backtest_cfg\"].get(\"risk_management\", {})\n",
    "    max_drawdown_stop = float(risk_cfg.get(\"max_drawdown_stop\", 0.5))\n",
    "    if state[\"current_drawdown\"] > max_drawdown_stop:\n",
    "        return True\n",
    "\n",
    "    if state[\"balance\"] < (0.1 * state[\"initial_balance\"]):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def _get_observation(state: Dict[str, Any]) -> np.ndarray:\n",
    "    \"\"\"Get the current observation.\"\"\"\n",
    "    start_idx = max(0, state[\"current_step\"] - state[\"lookback_window\"])\n",
    "\n",
    "    # Select features in the order defined by feature_names\n",
    "    df = state[\"processed_data\"]\n",
    "    if all(f in df.columns for f in state[\"feature_names\"]):\n",
    "        window = df[state[\"feature_names\"]].iloc[start_idx:state[\"current_step\"]]\n",
    "        n_cols = len(state[\"feature_names\"])\n",
    "    else:\n",
    "        # Fallback to all columns if mismatch\n",
    "        logger.warning(f\"Feature mismatch in observation. Expected: {state['feature_names']}, Available: {list(df.columns)}\")\n",
    "        window = df.iloc[start_idx:state[\"current_step\"]]\n",
    "        n_cols = window.shape[1]\n",
    "\n",
    "    # Pad if needed\n",
    "    if len(window) < state[\"lookback_window\"]:\n",
    "        n_missing = state[\"lookback_window\"] - len(window)\n",
    "        pad_shape = (n_missing, n_cols)\n",
    "        pad = np.zeros(pad_shape, dtype=np.float32)\n",
    "        window_vals = np.vstack([pad, window.values.astype(np.float32)])\n",
    "    else:\n",
    "        window_vals = window.values.astype(np.float32)\n",
    "\n",
    "    flat_market = window_vals.flatten()\n",
    "\n",
    "    portfolio_features = np.array([\n",
    "        state[\"balance\"] / float(state[\"initial_balance\"]),\n",
    "        state[\"position\"],\n",
    "        (state[\"unrealized_pnl\"] / float(state[\"initial_balance\"])) if state[\"initial_balance\"] != 0 else 0.0,\n",
    "        float(state[\"total_trades\"]) / 1000.0,\n",
    "        float(state[\"current_drawdown\"])\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "    obs = np.concatenate([flat_market.astype(np.float32), portfolio_features], axis=0)\n",
    "\n",
    "    # Ensure obs length matches expected obs_dim, pad or trim if necessary to keep deterministic shape\n",
    "    expected_len = int(state[\"observation_space\"].shape[0]) if \"observation_space\" in state else int(state[\"obs_dim\"])\n",
    "    if obs.shape[0] < expected_len:\n",
    "        pad_len = expected_len - obs.shape[0]\n",
    "        obs = np.concatenate([obs, np.zeros(pad_len, dtype=np.float32)], axis=0)\n",
    "    elif obs.shape[0] > expected_len:\n",
    "        obs = obs[:expected_len]\n",
    "        \n",
    "    # Final validation\n",
    "    if obs.shape[0] != expected_len:\n",
    "        logger.error(f\"Observation shape mismatch: got {obs.shape[0]}, expected {expected_len}\")\n",
    "        logger.error(f\"Market features: {flat_market.shape[0]}, Portfolio features: {portfolio_features.shape[0]}\")\n",
    "        logger.error(f\"Lookback window: {state['lookback_window']}, N features: {n_cols}\")\n",
    "\n",
    "    return obs\n",
    "\n",
    "def _get_info(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Get information about the current state.\"\"\"\n",
    "    pv = _get_portfolio_value(state)\n",
    "    win_rate = (float(state[\"winning_trades\"]) / float(max(1, state[\"total_trades\"]))) if state[\"total_trades\"] > 0 else 0.0\n",
    "    return {\n",
    "        \"step\": int(state[\"current_step\"]),\n",
    "        \"balance\": float(state[\"balance\"]),\n",
    "        \"position\": float(state[\"position\"]),\n",
    "        \"portfolio_value\": float(pv),\n",
    "        \"total_return\": float((pv - state[\"initial_balance\"]) / float(state[\"initial_balance\"])),\n",
    "        \"total_trades\": int(state[\"total_trades\"]),\n",
    "        \"winning_trades\": int(state[\"winning_trades\"]),\n",
    "        \"win_rate\": float(win_rate),\n",
    "        \"max_drawdown\": float(state[\"max_drawdown\"]),\n",
    "        \"current_drawdown\": float(state[\"current_drawdown\"]),\n",
    "        \"unrealized_pnl\": float(state[\"unrealized_pnl\"])\n",
    "    }\n",
    "\n",
    "def trading_env_render(state: Dict[str, Any]) -> None:\n",
    "    \"\"\"Render the current environment state.\"\"\"\n",
    "    if state[\"render_mode\"] == \"human\":\n",
    "        info = _get_info(state)\n",
    "        print(\n",
    "            f\"[Step {info['step']}] Balance: ${info['balance']:.2f} | \"\n",
    "            f\"Portfolio: ${info['portfolio_value']:.2f} | Return: {info['total_return']:.2%} | \"\n",
    "            f\"Drawdown: {info['current_drawdown']:.2%} | Position: {info['position']:.4f}\"\n",
    "        )\n",
    "\n",
    "def trading_env_build_for_model_loading(\n",
    "    data: pd.DataFrame,\n",
    "    config_path: str,\n",
    "    expected_signature: Dict[str, Any]\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Build environment for model loading with signature validation.\"\"\"\n",
    "    state = trading_env_init(data=data, config_path=config_path, expected_signature=expected_signature)\n",
    "    sig = trading_env_obs_signature(state)\n",
    "    if sig.get(\"obs_dim\") != expected_signature.get(\"obs_dim\"):\n",
    "        raise ValueError(\n",
    "            f\"obs_dim mismatch building env_for_model_loading: expected {expected_signature.get('obs_dim')}, got {sig.get('obs_dim')}\"\n",
    "        )\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8386557c",
   "metadata": {},
   "source": [
    "Setup and run Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9fa64b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingFeatureExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.Space, portfolio_features_dim: int = 5):\n",
    "        super().__init__(observation_space, features_dim=256)\n",
    "        self.portfolio_features_dim = portfolio_features_dim\n",
    "\n",
    "        total_obs_dim = int(observation_space.shape[0])\n",
    "        market_dim = total_obs_dim - self.portfolio_features_dim\n",
    "        if market_dim <= 0:\n",
    "            raise ValueError(\"Observation space too small for configured portfolio_features_dim\")\n",
    "\n",
    "        self.market_extractor = nn.Sequential(\n",
    "            nn.Linear(market_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.portfolio_extractor = nn.Sequential(\n",
    "            nn.Linear(self.portfolio_features_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.combined_extractor = nn.Sequential(\n",
    "            nn.Linear(128 + 32, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, obs: torch.Tensor) -> torch.Tensor:\n",
    "        market_features = obs[:, :-self.portfolio_features_dim]\n",
    "        portfolio_features = obs[:, -self.portfolio_features_dim:]\n",
    "        market_embed = self.market_extractor(market_features)\n",
    "        portfolio_embed = self.portfolio_extractor(portfolio_features)\n",
    "        combined = torch.cat([market_embed, portfolio_embed], dim=1)\n",
    "        return self.combined_extractor(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5543a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OBS_CONFIG_FILENAME = \"obs_config.yaml\"\n",
    "model_params = config['ppo']\n",
    "training_params = config['training']\n",
    "\n",
    "model: Optional[PPO] = None\n",
    "env: Optional[gym.Env] = None\n",
    "vec_env: Optional[VecNormalize] = None\n",
    "\n",
    "# Track policy kwargs used and a serializable snapshot\n",
    "_policy_kwargs_used: Optional[Dict[str, Any]] = None\n",
    "_policy_kwargs_serializable: Optional[Dict[str, Any]] = None\n",
    "\n",
    "def _read_yaml_if_exists(path: str) -> Optional[Dict[str, Any]]:\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            with open(path, 'r') as f:\n",
    "                return yaml.safe_load(f)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to read yaml at {path}: {e}\")\n",
    "    return None\n",
    "\n",
    "def _ensure_vec_env(env: Optional[gym.Env]) -> Optional[VecEnv]:\n",
    "    if env is None:\n",
    "        return None\n",
    "\n",
    "    if isinstance(env, VecEnv):\n",
    "        return env\n",
    "\n",
    "    base = env\n",
    "    try:\n",
    "        underlying = getattr(base, \"env\", None)\n",
    "        if underlying is not None and isinstance(underlying, gym.Env):\n",
    "            base = base\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        monitored = base if isinstance(base, Monitor) else Monitor(base)\n",
    "        return DummyVecEnv([lambda: monitored])\n",
    "    except Exception as exc:\n",
    "        raise ValueError(f\"Failed to wrap provided env into VecEnv: {exc}\")\n",
    "\n",
    "def _unwrap_env_for_obs_signature(env: Optional[gym.Env]):\n",
    "    if env is None:\n",
    "        return None\n",
    "\n",
    "    if isinstance(env, DummyVecEnv):\n",
    "        try:\n",
    "            inner = getattr(env, \"envs\", None)\n",
    "            if inner and len(inner) > 0:\n",
    "                return inner[0]\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    try:\n",
    "        inner = getattr(env, \"env\", None)\n",
    "        if inner is not None:\n",
    "            return inner\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return env\n",
    "\n",
    "def _map_activation_fn(act):\n",
    "    if isinstance(act, str):\n",
    "        act_map = {\n",
    "            \"relu\": nn.ReLU,\n",
    "            \"tanh\": nn.Tanh,\n",
    "            \"sigmoid\": nn.Sigmoid,\n",
    "            \"leaky_relu\": nn.LeakyReLU,\n",
    "            \"swish\": nn.SiLU,\n",
    "            \"gelu\": nn.GELU\n",
    "        }\n",
    "        return act_map.get(act.lower(), nn.ReLU)\n",
    "    if isinstance(act, type) and issubclass(act, nn.Module):\n",
    "        return act\n",
    "    return nn.ReLU\n",
    "\n",
    "def _serialize_policy_kwargs(pk: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    serial = {}\n",
    "    serial['net_arch'] = pk.get('net_arch')\n",
    "    act = pk.get('activation_fn')\n",
    "    if isinstance(act, type):\n",
    "        serial['activation_fn'] = act.__name__.lower()\n",
    "    else:\n",
    "        serial['activation_fn'] = str(act).lower() if act is not None else None\n",
    "\n",
    "    fe = pk.get('features_extractor_class')\n",
    "    serial['features_extractor_class'] = fe.__name__ if hasattr(fe, '__name__') else str(fe)\n",
    "    serial['features_extractor_kwargs'] = pk.get('features_extractor_kwargs', {})\n",
    "    serial['ortho_init'] = pk.get('ortho_init', None)\n",
    "\n",
    "    other = {k: v for k, v in pk.items() if k not in ['net_arch', 'activation_fn', 'features_extractor_class', 'features_extractor_kwargs', 'ortho_init']}\n",
    "    serial['other'] = other\n",
    "    serial['version'] = 1\n",
    "    return serial\n",
    "\n",
    "def _deserialize_policy_kwargs(serialized: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    if not serialized:\n",
    "        return {}\n",
    "    pk: Dict[str, Any] = {}\n",
    "    if 'net_arch' in serialized and serialized['net_arch'] is not None:\n",
    "        pk['net_arch'] = serialized['net_arch']\n",
    "    act_name = serialized.get('activation_fn')\n",
    "    if act_name:\n",
    "        pk['activation_fn'] = _map_activation_fn(act_name)\n",
    "    fe_name = serialized.get('features_extractor_class')\n",
    "    if fe_name and fe_name.lower().startswith('tradingfeatureextractor'):\n",
    "        pk['features_extractor_class'] = TradingFeatureExtractor\n",
    "    pk['features_extractor_kwargs'] = serialized.get('features_extractor_kwargs', {}) or {}\n",
    "    if 'ortho_init' in serialized:\n",
    "        pk['ortho_init'] = serialized.get('ortho_init')\n",
    "    other = serialized.get('other', {}) or {}\n",
    "    pk.update(other)\n",
    "    return pk\n",
    "\n",
    "def _build_eval_vec_env(eval_data: pd.DataFrame, vec_env: Optional[VecNormalize], model_dir: Optional[str] = None) -> VecNormalize:\n",
    "    expected_signature = None\n",
    "    if model_dir:\n",
    "        sig_path = os.path.join(model_dir, OBS_CONFIG_FILENAME)\n",
    "        expected_signature = _read_yaml_if_exists(sig_path)\n",
    "\n",
    "    eval_env = TradingEnvironment(\n",
    "        data=eval_data,\n",
    "        config_path=\"config/model_config.yaml\",\n",
    "        **({\"expected_signature\": expected_signature} if expected_signature is not None else {})\n",
    "    )\n",
    "    eval_env = Monitor(eval_env)\n",
    "    eval_vec = DummyVecEnv([lambda: eval_env])\n",
    "\n",
    "    eval_vec_norm = VecNormalize(eval_vec, norm_obs=True, norm_reward=False, training=False)\n",
    "\n",
    "    if isinstance(vec_env, VecNormalize) and getattr(vec_env, \"obs_rms\", None) is not None:\n",
    "        eval_vec_norm.obs_rms = vec_env.obs_rms\n",
    "\n",
    "    return eval_vec_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8342649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VECNORM_FILENAME = \"vecnormalize.pkl\"\n",
    "OBS_CONFIG_FILENAME = \"obs_config.yaml\"\n",
    "POLICY_KWARGS_FILENAME = \"policy_kwargs.yaml\"\n",
    "\n",
    "def train(\n",
    "    model: Optional[PPO],\n",
    "    vec_env: Optional[VecNormalize],\n",
    "    env: Optional[gym.Env],\n",
    "    config: Dict[str, Any],\n",
    "    training_params: Dict[str, Any],\n",
    "    policy_kwargs_serializable: Optional[Dict[str, Any]],\n",
    "    train_data: pd.DataFrame,\n",
    "    eval_data: Optional[pd.DataFrame] = None\n",
    ") -> Tuple[Dict[str, Any], Optional[PPO], Optional[VecNormalize], Optional[gym.Env], Optional[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Train a PPO model with the provided data and parameters.\n",
    "    \n",
    "    Returns: (result_dict, updated_model, updated_vec_env, updated_env, updated_policy_kwargs_serializable)\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        # Create model logic would need to be implemented separately\n",
    "        raise ValueError(\"Model must be created before training\")\n",
    "\n",
    "    logger.info(f\"Starting PPO training with {len(train_data)} samples\")\n",
    "\n",
    "    callbacks = [\n",
    "        CheckpointCallback(\n",
    "            save_freq=training_params.get('save_freq', 5000),\n",
    "            save_path='./models/saved_models/checkpoints/',\n",
    "            name_prefix='ppo_trading'\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    if eval_data is not None:\n",
    "        eval_vec_norm = _build_eval_vec_env(eval_data, vec_env)\n",
    "        callbacks.append(EvalCallback(\n",
    "            eval_vec_norm,\n",
    "            eval_freq=training_params.get('eval_freq', 10000),\n",
    "            n_eval_episodes=training_params.get('n_eval_episodes', 5),\n",
    "            best_model_save_path='./models/saved_models/',\n",
    "            log_path='./logs/eval/',\n",
    "            verbose=1\n",
    "        ))\n",
    "\n",
    "    total_timesteps = training_params['total_timesteps']\n",
    "\n",
    "    try:\n",
    "        model.learn(total_timesteps=total_timesteps, callback=callbacks, progress_bar=True)\n",
    "\n",
    "        model_path = f\"./models/saved_models/ppo_final.zip\"\n",
    "        os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "        model.save(model_path)\n",
    "\n",
    "        try:\n",
    "            vecnorm_path = os.path.join(os.path.dirname(model_path), VECNORM_FILENAME)\n",
    "            if isinstance(vec_env, VecNormalize):\n",
    "                vec_env.save(vecnorm_path)\n",
    "                logger.info(f\"Saved VecNormalize stats to {vecnorm_path}\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not save VecNormalize stats: {e}\")\n",
    "\n",
    "        try:\n",
    "            base_env = _unwrap_env_for_obs_signature(env)\n",
    "            obs_sig_fn = getattr(base_env, \"obs_signature\", None)\n",
    "            if callable(obs_sig_fn):\n",
    "                obs_sig = obs_sig_fn()\n",
    "                with open(os.path.join(os.path.dirname(model_path), OBS_CONFIG_FILENAME), \"w\") as f:\n",
    "                    yaml.safe_dump(obs_sig, f)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not save {OBS_CONFIG_FILENAME}: {e}\")\n",
    "\n",
    "        try:\n",
    "            # prefer serializable snapshot created earlier\n",
    "            policy_to_save = policy_kwargs_serializable or _serialize_policy_kwargs(config['ppo'].get('policy_kwargs', {}))\n",
    "            with open(os.path.join(os.path.dirname(model_path), POLICY_KWARGS_FILENAME), \"w\") as f:\n",
    "                yaml.safe_dump(policy_to_save, f)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not save {POLICY_KWARGS_FILENAME}: {e}\")\n",
    "\n",
    "        logger.info(f\"Training completed. Model saved to {model_path}\")\n",
    "\n",
    "        training_cb = callbacks[0]\n",
    "        result = {\n",
    "            'success': True,\n",
    "            'model_path': model_path,\n",
    "            'total_timesteps': total_timesteps,\n",
    "            'best_model_path': getattr(training_cb, 'best_model_path', None),\n",
    "            'final_performance': {\n",
    "                'mean_reward': training_cb.best_mean_reward,\n",
    "                'total_episodes': len(training_cb.episode_rewards)\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return result, model, vec_env, env, policy_kwargs_serializable\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Training failed: {e}\")\n",
    "        return {'success': False, 'error': str(e)}, model, vec_env, env, policy_kwargs_serializable\n",
    "\n",
    "def predict(\n",
    "    model: PPO,\n",
    "    observation: np.ndarray,\n",
    "    deterministic: bool = True\n",
    ") -> Tuple[np.ndarray, Optional[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Predict an action given an observation using the trained model.\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        raise ValueError(\"Model not loaded. Call create_model() or train() first.\")\n",
    "\n",
    "    # Check for NaN in input\n",
    "    if np.any(np.isnan(observation)):\n",
    "        logger.warning(\"NaN values in observation input\")\n",
    "        observation = np.nan_to_num(observation)\n",
    "    \n",
    "    action, _ = model.predict(observation, deterministic=deterministic)\n",
    "    return action, None\n",
    "\n",
    "def evaluate(\n",
    "    model: PPO,\n",
    "    eval_data: pd.DataFrame,\n",
    "    vec_env: Optional[VecNormalize],\n",
    "    n_episodes: int = 10\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate the model on the provided evaluation data.\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        raise ValueError(\"Model not loaded. Call create_model() or train() first.\")\n",
    "\n",
    "    model_dir = None\n",
    "    eval_vec_norm = _build_eval_vec_env(eval_data, vec_env, model_dir=model_dir)\n",
    "\n",
    "    episode_returns, episode_lengths, win_rates, max_drawdowns = [], [], [], []\n",
    "\n",
    "    for episode in range(n_episodes):\n",
    "        obs = eval_vec_norm.reset()\n",
    "        done = [False]\n",
    "        ep_ret = 0.0\n",
    "        ep_len = 0\n",
    "        last_info: Dict[str, Any] = {}\n",
    "\n",
    "        while not done[0]:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, rewards, done, infos = eval_vec_norm.step(action)\n",
    "            ep_ret += float(rewards[0])\n",
    "            ep_len += 1\n",
    "            if isinstance(infos, (list, tuple)) and len(infos) > 0 and isinstance(infos[0], dict):\n",
    "                last_info = infos[0] or last_info\n",
    "\n",
    "        episode_returns.append(ep_ret)\n",
    "        episode_lengths.append(ep_len)\n",
    "        win_rates.append(last_info.get('win_rate', 0.0))\n",
    "        max_drawdowns.append(last_info.get('max_drawdown', 0.0))\n",
    "\n",
    "        logger.info(f\"Evaluation episode {episode + 1}/{n_episodes}: Return={ep_ret:.2f}, Length={ep_len}\")\n",
    "\n",
    "    return {\n",
    "        'mean_return': float(np.mean(episode_returns)),\n",
    "        'std_return': float(np.std(episode_returns)),\n",
    "        'mean_length': float(np.mean(episode_lengths)),\n",
    "        'mean_win_rate': float(np.mean(win_rates)),\n",
    "        'mean_max_drawdown': float(np.mean(max_drawdowns)),\n",
    "        'sharpe_ratio': float(np.mean(episode_returns) / (np.std(episode_returns) + 1e-8))\n",
    "    }\n",
    "\n",
    "def save_model(\n",
    "    model: PPO,\n",
    "    vec_env: Optional[VecNormalize],\n",
    "    env: Optional[gym.Env],\n",
    "    config: Dict[str, Any],\n",
    "    policy_kwargs_serializable: Optional[Dict[str, Any]],\n",
    "    path: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Save the model and related files to the specified path.\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        raise ValueError(\"No model to save\")\n",
    "    os.makedirs(os.path.dirname(path) or \".\", exist_ok=True)\n",
    "\n",
    "    model.save(path)\n",
    "\n",
    "    if isinstance(vec_env, VecNormalize):\n",
    "        try:\n",
    "            vec_env.save(os.path.join(os.path.dirname(path) or \".\", VECNORM_FILENAME))\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not save VecNormalize stats on save_model: {e}\")\n",
    "\n",
    "    try:\n",
    "        base_env = _unwrap_env_for_obs_signature(env)\n",
    "        obs_sig_fn = getattr(base_env, \"obs_signature\", None)\n",
    "        if callable(obs_sig_fn):\n",
    "            obs_sig = obs_sig_fn()\n",
    "            with open(os.path.join(os.path.dirname(path) or \".\", OBS_CONFIG_FILENAME), \"w\") as f:\n",
    "                yaml.safe_dump(obs_sig, f)\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not save obs_config.yaml: {e}\")\n",
    "\n",
    "    try:\n",
    "        policy_to_save = policy_kwargs_serializable or _serialize_policy_kwargs(config['ppo'].get('policy_kwargs', {}))\n",
    "        with open(os.path.join(os.path.dirname(path) or \".\", POLICY_KWARGS_FILENAME), \"w\") as f:\n",
    "            yaml.safe_dump(policy_to_save, f)\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not save policy_kwargs.yaml: {e}\")\n",
    "\n",
    "    logger.info(f\"Model saved to {path}\")\n",
    "\n",
    "def load_model(\n",
    "    path: str,\n",
    "    env: Optional[gym.Env] = None,\n",
    "    policy_kwargs_serializable: Optional[Dict[str, Any]] = None\n",
    ") -> Tuple[PPO, Optional[VecNormalize], Optional[gym.Env], Optional[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Load a model from the specified path.\n",
    "    \n",
    "    Returns: (model, vec_env, env, policy_kwargs_serializable)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Model file not found: {path}\")\n",
    "\n",
    "    model_dir = os.path.dirname(path)\n",
    "\n",
    "    policy_kwargs_path = os.path.join(model_dir, POLICY_KWARGS_FILENAME)\n",
    "    policy_kwargs_serial = _read_yaml_if_exists(policy_kwargs_path) or {}\n",
    "    # deserialize into runtime objects\n",
    "    try:\n",
    "        policy_kwargs = _deserialize_policy_kwargs(policy_kwargs_serial)\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Failed to deserialize policy kwargs from file: {e}\")\n",
    "        policy_kwargs = {}\n",
    "\n",
    "    policy_kwargs.setdefault(\"features_extractor_class\", TradingFeatureExtractor)\n",
    "    policy_kwargs.setdefault(\"features_extractor_kwargs\", {\"portfolio_features_dim\": 5})\n",
    "\n",
    "    vec_env_loaded = None\n",
    "    vecnorm_path = os.path.join(model_dir, VECNORM_FILENAME)\n",
    "    if os.path.exists(vecnorm_path):\n",
    "        if env is None:\n",
    "            raise ValueError(\n",
    "                f\"Model appears to use VecNormalize (found {VECNORM_FILENAME}). Provide a real environment with matching observation signature when loading.\"\n",
    "            )\n",
    "        env_vec = _ensure_vec_env(env)\n",
    "\n",
    "        obs_sig_path = os.path.join(model_dir, OBS_CONFIG_FILENAME)\n",
    "        expected_sig = _read_yaml_if_exists(obs_sig_path)\n",
    "        if expected_sig is not None:\n",
    "            underlying = _unwrap_env_for_obs_signature(env)\n",
    "            obs_sig_fn = getattr(underlying, \"obs_signature\", None)\n",
    "            if callable(obs_sig_fn):\n",
    "                current_sig = obs_sig_fn()\n",
    "                logger.info(f\"Expected signature: {expected_sig}\")\n",
    "                logger.info(f\"Current signature: {current_sig}\")\n",
    "                if int(current_sig.get(\"obs_dim\", -1)) != int(expected_sig.get(\"obs_dim\", -1)):\n",
    "                    raise RuntimeError(\n",
    "                        f\"Saved model obs_dim={expected_sig.get('obs_dim')} does not match provided env obs_dim={current_sig.get('obs_dim')}. Create an environment with matching features/lookback or retrain the model.\"\n",
    "                    )\n",
    "                \n",
    "                # Validate feature consistency\n",
    "                expected_features = expected_sig.get(\"feature_names\", [])\n",
    "                current_features = current_sig.get(\"feature_names\", [])\n",
    "                if expected_features != current_features:\n",
    "                    logger.warning(f\"Feature mismatch - Expected: {len(expected_features)}, Current: {len(current_features)}\")\n",
    "                    logger.warning(f\"Expected features: {expected_features}\")\n",
    "                    logger.warning(f\"Current features: {current_features}\")\n",
    "                    \n",
    "                    # Check if it's just ordering or missing features\n",
    "                    missing_features = set(expected_features) - set(current_features)\n",
    "                    extra_features = set(current_features) - set(expected_features)\n",
    "                    \n",
    "                    if missing_features:\n",
    "                        raise RuntimeError(f\"Missing features in current environment: {missing_features}\")\n",
    "                    if extra_features:\n",
    "                        logger.warning(f\"Extra features in current environment (will be ignored): {extra_features}\")\n",
    "        \n",
    "        vec_env_loaded = VecNormalize.load(vecnorm_path, env_vec)\n",
    "        vec_env_loaded.training = False\n",
    "        vec_env_loaded.norm_reward = False\n",
    "        env = vec_env_loaded\n",
    "        logger.info(f\"Loaded VecNormalize stats from {vecnorm_path}\")\n",
    "    elif env is not None:\n",
    "        vec_env_loaded = env\n",
    "\n",
    "    try:\n",
    "        model = PPO.load(path, env=env, custom_objects={\"policy_kwargs\": policy_kwargs})\n",
    "        # record policy kwargs used\n",
    "        policy_kwargs_used = getattr(model, 'policy_kwargs', policy_kwargs)\n",
    "        if policy_kwargs_used:\n",
    "            policy_kwargs_serializable = _serialize_policy_kwargs(policy_kwargs_used)\n",
    "        logger.info(f\"Model loaded from {path}\")\n",
    "        return model, vec_env_loaded, env, policy_kwargs_serializable\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load model due to: {e}\")\n",
    "        raise\n",
    "\n",
    "def create_model(train_data: pd.DataFrame, model_path: Optional[str] = None) -> None:\n",
    "        env = TradingEnvironment(\n",
    "            data=train_data,\n",
    "            config_path=\"config/model_config.yaml\"\n",
    "        )\n",
    "        env = Monitor(TradingEnvironment)\n",
    "        train_vec = DummyVecEnv([lambda: env])\n",
    "        vec_env = VecNormalize(train_vec, norm_obs=True, norm_reward=True)\n",
    "\n",
    "        if model_path and os.path.exists(model_path):\n",
    "            logger.info(f\"Loading model from {model_path}\")\n",
    "\n",
    "            model_dir = os.path.dirname(model_path)\n",
    "            policy_kwargs_path = os.path.join(model_dir, POLICY_KWARGS_FILENAME)\n",
    "            saved_policy_kwargs = _read_yaml_if_exists(policy_kwargs_path)\n",
    "\n",
    "            custom_objects = {\"learning_rate\": model_params.get('learning_rate')}\n",
    "            if saved_policy_kwargs:\n",
    "                try:\n",
    "                    deserialized = _deserialize_policy_kwargs(saved_policy_kwargs)\n",
    "                    # Ensure feature extractor present\n",
    "                    deserialized.setdefault(\"features_extractor_class\", TradingFeatureExtractor)\n",
    "                    deserialized.setdefault(\"features_extractor_kwargs\", {\"portfolio_features_dim\": 5})\n",
    "                    custom_objects[\"policy_kwargs\"] = deserialized\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Failed to deserialize saved policy kwargs: {e}\")\n",
    "\n",
    "            try:\n",
    "                model = PPO.load(model_path, env=vec_env, custom_objects=custom_objects)\n",
    "                # store policy kwargs used if available\n",
    "                _policy_kwargs_used = getattr(model, 'policy_kwargs', custom_objects.get('policy_kwargs'))\n",
    "                if _policy_kwargs_used:\n",
    "                    _policy_kwargs_serializable = _serialize_policy_kwargs(_policy_kwargs_used)\n",
    "                logger.info(\"PPO model loaded successfully for continued training\")\n",
    "                return\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to load model for continued training: {e}\")\n",
    "                raise\n",
    "\n",
    "        logger.info(\"Creating new PPO model\")\n",
    "\n",
    "        policy_kwargs = dict(model_params.get(\"policy_kwargs\", {}) or {})\n",
    "\n",
    "        act_fn = policy_kwargs.get(\"activation_fn\")\n",
    "        if isinstance(act_fn, str):\n",
    "            policy_kwargs[\"activation_fn\"] = _map_activation_fn(act_fn)\n",
    "\n",
    "        if model_params.get(\"use_custom_policy\", True):\n",
    "            extractor_kwargs = policy_kwargs.pop('features_extractor_kwargs', {}) or {}\n",
    "            extractor_kwargs.update({'portfolio_features_dim': 5})\n",
    "            policy_kwargs.update({\n",
    "                'features_extractor_class': TradingFeatureExtractor,\n",
    "                'features_extractor_kwargs': extractor_kwargs\n",
    "            })\n",
    "\n",
    "        # store used policy kwargs for later serialization\n",
    "        _policy_kwargs_used = policy_kwargs\n",
    "        _policy_kwargs_serializable = _serialize_policy_kwargs(policy_kwargs)\n",
    "\n",
    "        model = PPO(\n",
    "            policy='MlpPolicy',\n",
    "            env=vec_env,\n",
    "            learning_rate=model_params['learning_rate'],\n",
    "            n_steps=model_params['n_steps'],\n",
    "            batch_size=model_params['batch_size'],\n",
    "            n_epochs=model_params['n_epochs'],\n",
    "            gamma=model_params['gamma'],\n",
    "            gae_lambda=model_params['gae_lambda'],\n",
    "            clip_range=model_params['clip_range'],\n",
    "            ent_coef=model_params['ent_coef'],\n",
    "            vf_coef=model_params['vf_coef'],\n",
    "            max_grad_norm=model_params['max_grad_norm'],\n",
    "            policy_kwargs=policy_kwargs,\n",
    "            verbose=1,\n",
    "            device='auto'\n",
    "        )\n",
    "\n",
    "        logger.info(\"PPO model created successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d23cce4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-08-28 01:52:30.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_prepare_data\u001b[0m:\u001b[36m194\u001b[0m - \u001b[1mData prepared: 47224 samples, 17 features\u001b[0m\n",
      "\u001b[32m2025-08-28 01:52:30.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_setup_spaces\u001b[0m:\u001b[36m222\u001b[0m - \u001b[1mAction space: Discrete(3)\u001b[0m\n",
      "\u001b[32m2025-08-28 01:52:30.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_setup_spaces\u001b[0m:\u001b[36m223\u001b[0m - \u001b[1mObservation space: (1705,)\u001b[0m\n",
      "\u001b[32m2025-08-28 01:52:30.671\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m85\u001b[0m - \u001b[1mTrading environment initialized with 47224 data points\u001b[0m\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Expected env to be a `gymnasium.Env` but got <class 'type'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run training\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model, env, vec_env, config, training_params, policy_kwargs_serializable = \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels/saved_models\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m results, updated_model, updated_vec_env, updated_env, updated_policy_kwargs = train(\n\u001b[32m      5\u001b[39m     model=model,\n\u001b[32m      6\u001b[39m     vec_env=vec_env,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     session_id=\u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Pass your session ID if available\u001b[39;00m\n\u001b[32m     16\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Update references to the potentially updated objects\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 301\u001b[39m, in \u001b[36mcreate_model\u001b[39m\u001b[34m(train_data, model_path)\u001b[39m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_model\u001b[39m(train_data: pd.DataFrame, model_path: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    297\u001b[39m         env = TradingEnvironment(\n\u001b[32m    298\u001b[39m             data=train_data,\n\u001b[32m    299\u001b[39m             config_path=\u001b[33m\"\u001b[39m\u001b[33mconfig/model_config.yaml\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    300\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m         env = \u001b[43mMonitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTradingEnvironment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m         train_vec = DummyVecEnv([\u001b[38;5;28;01mlambda\u001b[39;00m: env])\n\u001b[32m    303\u001b[39m         vec_env = VecNormalize(train_vec, norm_obs=\u001b[38;5;28;01mTrue\u001b[39;00m, norm_reward=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\stable_baselines3\\common\\monitor.py:40\u001b[39m, in \u001b[36mMonitor.__init__\u001b[39m\u001b[34m(self, env, filename, allow_early_resets, reset_keywords, info_keywords, override_existing)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     32\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     33\u001b[39m     env: gym.Env,\n\u001b[32m   (...)\u001b[39m\u001b[32m     38\u001b[39m     override_existing: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     39\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m=\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mself\u001b[39m.t_start = time.time()\n\u001b[32m     42\u001b[39m     \u001b[38;5;28mself\u001b[39m.results_writer = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\gymnasium\\core.py:313\u001b[39m, in \u001b[36mWrapper.__init__\u001b[39m\u001b[34m(self, env)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Wraps an environment to allow a modular transformation of the :meth:`step` and :meth:`reset` methods.\u001b[39;00m\n\u001b[32m    308\u001b[39m \n\u001b[32m    309\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    310\u001b[39m \u001b[33;03m    env: The environment to wrap\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    312\u001b[39m \u001b[38;5;28mself\u001b[39m.env = env\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    314\u001b[39m     env, Env\n\u001b[32m    315\u001b[39m ), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected env to be a `gymnasium.Env` but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(env)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;28mself\u001b[39m._action_space: spaces.Space[WrapperActType] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    318\u001b[39m \u001b[38;5;28mself\u001b[39m._observation_space: spaces.Space[WrapperObsType] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: Expected env to be a `gymnasium.Env` but got <class 'type'>"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "model, env, vec_env, config, training_params, policy_kwargs_serializable = create_model(data, \"models/saved_models\")\n",
    "\n",
    "results, updated_model, updated_vec_env, updated_env, updated_policy_kwargs = train(\n",
    "    model=model,\n",
    "    vec_env=vec_env,\n",
    "    env=env,\n",
    "    config=config,\n",
    "    training_params=training_params,\n",
    "    websocket_broadcaster=None,  # Pass your websocket broadcaster if available\n",
    "    performance_tracker=None,    # Pass your performance tracker if available\n",
    "    policy_kwargs_serializable=policy_kwargs_serializable,\n",
    "    train_data=train_data,\n",
    "    eval_data=eval_data,\n",
    "    session_id=None  # Pass your session ID if available\n",
    ")\n",
    "\n",
    "# Update references to the potentially updated objects\n",
    "model = updated_model\n",
    "vec_env = updated_vec_env\n",
    "env = updated_env\n",
    "policy_kwargs_serializable = updated_policy_kwargs\n",
    "\n",
    "logger.info(f\"Training completed for {symbol_name}: {results}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
